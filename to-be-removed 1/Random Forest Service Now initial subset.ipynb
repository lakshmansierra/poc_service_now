{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9050b97-cfeb-453f-9727-928bd9b7b28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 23:07:29,623 - INFO - Databricks Random Forest Predictor initialized\n2025-06-12 23:07:29,629 - INFO - Starting full Random Forest prediction pipeline\n2025-06-12 23:07:29,629 - INFO - Reading data from table: sd_bdc_demo.default.service_now_only\n2025-06-12 23:07:40,898 - INFO - Loaded 111 rows, 20 columns from sd_bdc_demo.default.service_now_only\n2025-06-12 23:07:40,899 - INFO - Starting data cleaning and preparation\n2025-06-12 23:07:44,657 - INFO - Data cleaning completed. Shape: (111, 29)\n2025-06-12 23:07:44,659 - INFO - Risk level distribution:\nLow       67\nHigh      37\nMedium     7\nName: Risk_Level, dtype: int64\n2025-06-12 23:07:44,660 - INFO - Creating features for Random Forest model\n2025-06-12 23:07:44,669 - INFO - Created 13 features: ['Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend', 'Asset_Incident_Count', 'Asset_Encoded', 'Category_Encoded', 'Subcategory_Encoded', 'Status_Encoded', 'Assigned_Group_Encoded', 'Location_Clean_Encoded', 'Incident_Type_Encoded']\n2025-06-12 23:07:44,675 - INFO - Training Random Forest models\n2025-06-12 23:07:45,621 - INFO - Model training completed:\n2025-06-12 23:07:45,623 - INFO - - Classification accuracy: 0.957\n2025-06-12 23:07:45,624 - INFO - - Regression MAE: 0.037\n2025-06-12 23:07:45,627 - INFO - - Top 3 features: ['Priority_Num', 'Status_Encoded', 'Asset_Encoded']\n2025-06-12 23:07:45,629 - INFO - Training results: {'classification_accuracy': 0.9565217391304348, 'regression_mae': 0.036776326933935614, 'feature_importance': {'Priority_Num': 0.3669796532021973, 'Status_Encoded': 0.11946767388060761, 'Asset_Encoded': 0.07773353969952916, 'Category_Encoded': 0.07548141263754005, 'Subcategory_Encoded': 0.06704926727275444, 'Location_Clean_Encoded': 0.05671333051565406, 'Assigned_Group_Encoded': 0.045176565719158054, 'Day_of_Month': 0.04364631332764702, 'Incident_Type_Encoded': 0.03793126285733359, 'Hour_of_Day': 0.03742627746335295, 'Asset_Incident_Count': 0.03279518751326661, 'Day_of_Week': 0.032378782392310575, 'Is_Weekend': 0.007220733518648597}, 'risk_label_encoder': LabelEncoder(), 'n_samples': 111, 'n_features': 13}\n2025-06-12 23:07:45,630 - INFO - Making predictions with Random Forest models\n2025-06-12 23:07:45,668 - INFO - Predictions completed for 111 records\n2025-06-12 23:07:45,669 - INFO - Saving predictions to Databricks table: sd_bdc_demo.default.service_now_rf_predictions\n2025-06-12 23:07:51,259 - INFO - Successfully saved 111 predictions to sd_bdc_demo.default.service_now_rf_predictions\n2025-06-12 23:07:51,259 - INFO - Sample predictions:\n2025-06-12 23:07:51,261 - INFO - Asset: Access Control System, Risk Score: 1.10, Level: 1\n2025-06-12 23:07:51,262 - INFO - Asset: HVAC System, Risk Score: 2.14, Level: 0\n2025-06-12 23:07:51,263 - INFO - Asset: Canon ImageRunner, Risk Score: 0.63, Level: 1\n2025-06-12 23:07:51,264 - INFO - Asset: Cisco IP Phone, Risk Score: 1.10, Level: 1\n2025-06-12 23:07:51,264 - INFO - Asset: Cisco Switch, Risk Score: 2.13, Level: 0\n2025-06-12 23:07:51,265 - INFO - === PREDICTION SUMMARY REPORT ===\n2025-06-12 23:07:51,269 - INFO - Risk Level Distribution: {1: 69, 0: 37, 2: 5}\n2025-06-12 23:07:51,274 - INFO - Top 5 Risk Assets:\n2025-06-12 23:07:51,276 - INFO -   - Identity Provider: 2.30\n2025-06-12 23:07:51,277 - INFO -   - Finance App Server: 2.29\n2025-06-12 23:07:51,278 - INFO -   - SQL Server: 2.18\n2025-06-12 23:07:51,279 - INFO -   - SQL Server: 2.17\n2025-06-12 23:07:51,281 - INFO -   - Domain Controller: 2.14\n2025-06-12 23:07:51,281 - INFO - Top 5 Feature Importance:\n2025-06-12 23:07:51,283 - INFO -   - Priority_Num: 0.367\n2025-06-12 23:07:51,283 - INFO -   - Status_Encoded: 0.119\n2025-06-12 23:07:51,285 - INFO -   - Asset_Encoded: 0.078\n2025-06-12 23:07:51,285 - INFO -   - Category_Encoded: 0.075\n2025-06-12 23:07:51,287 - INFO -   - Subcategory_Encoded: 0.067\n2025-06-12 23:07:51,288 - INFO - Total assets analyzed: 59\n2025-06-12 23:07:51,289 - INFO - Total predictions made: 111\n2025-06-12 23:07:51,289 - INFO - Pipeline completed successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest prediction pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Databricks Random Forest Incident Prediction System\n",
    "==================================================\n",
    "\n",
    "This program reads incident data from a Databricks table, performs Random Forest\n",
    "prediction for asset risk scoring, and writes results back to Databricks.\n",
    "\n",
    "Requirements:\n",
    "- databricks-connect or running in Databricks environment\n",
    "- pandas, scikit-learn, numpy\n",
    "- Access to source and target Databricks tables\n",
    "\n",
    "Author: ML Prediction System\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Databricks/Spark imports\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, regexp_extract, to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, TimestampType\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabricksRandomForestPredictor:\n",
    "    \"\"\"\n",
    "    Random Forest predictor for IT incident risk analysis using Databricks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, spark_session: Optional[SparkSession] = None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with Spark session\n",
    "        \n",
    "        Args:\n",
    "            spark_session: Optional SparkSession, creates new one if None\n",
    "        \"\"\"\n",
    "        self.spark = spark_session or SparkSession.builder.appName(\"IncidentRiskPredictor\").getOrCreate()\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.rf_classifier = None\n",
    "        self.rf_regressor = None\n",
    "        self.feature_columns = []\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "        logger.info(\"Databricks Random Forest Predictor initialized\")\n",
    "    \n",
    "    def read_incident_data(self, table_name: str) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Read incident data from Databricks table\n",
    "        \n",
    "        Args:\n",
    "            table_name: Name of the Databricks table (e.g., 'default.incidents')\n",
    "            \n",
    "        Returns:\n",
    "            Spark DataFrame with incident data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Reading data from table: {table_name}\")\n",
    "            \n",
    "            # Read from Databricks table\n",
    "            df = self.spark.table(table_name)\n",
    "            \n",
    "            # Log data info\n",
    "            row_count = df.count()\n",
    "            col_count = len(df.columns)\n",
    "            logger.info(f\"Loaded {row_count} rows, {col_count} columns from {table_name}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading from table {table_name}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_and_prepare_data(self, df: DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clean and prepare incident data for ML processing\n",
    "        \n",
    "        Args:\n",
    "            df: Raw Spark DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Cleaned pandas DataFrame ready for ML\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting data cleaning and preparation\")\n",
    "        \n",
    "        try:\n",
    "            # Convert to pandas for easier processing\n",
    "            pdf = df.toPandas()\n",
    "            \n",
    "            # Clean column names (remove spaces, special characters)\n",
    "            pdf.columns = [col.strip().replace(' ', '_').replace('/', '_') for col in pdf.columns]\n",
    "            \n",
    "            # Parse dates\n",
    "            date_columns = ['Created_Date', 'Last_Modified', 'Resolved_Date', 'SLA_Due']\n",
    "            for col in date_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pd.to_datetime(pdf[col], errors='coerce')\n",
    "            \n",
    "            # Extract priority numbers\n",
    "            if 'Priority' in pdf.columns:\n",
    "                pdf['Priority_Num'] = pdf['Priority'].str.extract(r'(\\d+)').astype(float)\n",
    "                pdf['Priority_Num'] = pdf['Priority_Num'].fillna(3)  # Default to moderate\n",
    "            \n",
    "            # Clean asset names\n",
    "            if 'CI' in pdf.columns:\n",
    "                pdf['Asset_Name'] = pdf['CI'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Clean locations\n",
    "            if 'Location' in pdf.columns:\n",
    "                pdf['Location_Clean'] = pdf['Location'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Calculate resolution times (hours)\n",
    "            if 'Created_Date' in pdf.columns and 'Resolved_Date' in pdf.columns:\n",
    "                pdf['Resolution_Hours'] = (\n",
    "                    pdf['Resolved_Date'] - pdf['Created_Date']\n",
    "                ).dt.total_seconds() / 3600\n",
    "                pdf['Resolution_Hours'] = pdf['Resolution_Hours'].fillna(0)\n",
    "            \n",
    "            # Create time-based features\n",
    "            if 'Created_Date' in pdf.columns:\n",
    "                pdf['Day_of_Week'] = pdf['Created_Date'].dt.dayofweek\n",
    "                pdf['Hour_of_Day'] = pdf['Created_Date'].dt.hour\n",
    "                pdf['Day_of_Month'] = pdf['Created_Date'].dt.day\n",
    "                pdf['Is_Weekend'] = pdf['Day_of_Week'].isin([5, 6]).astype(int)\n",
    "            \n",
    "            # Create risk labels based on priority and resolution time\n",
    "            pdf['Risk_Level'] = 'Low'\n",
    "            if 'Priority_Num' in pdf.columns:\n",
    "                pdf.loc[pdf['Priority_Num'] == 1, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[pdf['Priority_Num'] == 2, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[(pdf['Priority_Num'] == 3) & (pdf.get('Resolution_Hours', 0) > 24), 'Risk_Level'] = 'Medium'\n",
    "            \n",
    "            # Fill missing values\n",
    "            categorical_columns = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Incident_Type']\n",
    "            for col in categorical_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pdf[col].fillna('Unknown')\n",
    "            \n",
    "            logger.info(f\"Data cleaning completed. Shape: {pdf.shape}\")\n",
    "            logger.info(f\"Risk level distribution:\\n{pdf['Risk_Level'].value_counts()}\")\n",
    "            \n",
    "            return pdf\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in data cleaning: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        \"\"\"\n",
    "        Create features for Random Forest model\n",
    "        \n",
    "        Args:\n",
    "            df: Cleaned pandas DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (feature DataFrame, list of feature column names)\n",
    "        \"\"\"\n",
    "        logger.info(\"Creating features for Random Forest model\")\n",
    "        \n",
    "        try:\n",
    "            features_df = df.copy()\n",
    "            \n",
    "            # Asset-based features\n",
    "            if 'Asset_Name' in df.columns:\n",
    "                # Count incidents per asset\n",
    "                asset_counts = df['Asset_Name'].value_counts()\n",
    "                features_df['Asset_Incident_Count'] = features_df['Asset_Name'].map(asset_counts)\n",
    "                \n",
    "                # Encode asset names\n",
    "                if 'Asset_Name' not in self.label_encoders:\n",
    "                    self.label_encoders['Asset_Name'] = LabelEncoder()\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].fit_transform(features_df['Asset_Name'])\n",
    "                else:\n",
    "                    # Handle new assets not seen during training\n",
    "                    known_assets = set(self.label_encoders['Asset_Name'].classes_)\n",
    "                    features_df['Asset_Name_Clean'] = features_df['Asset_Name'].apply(\n",
    "                        lambda x: x if x in known_assets else 'Unknown'\n",
    "                    )\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].transform(features_df['Asset_Name_Clean'])\n",
    "            \n",
    "            # Categorical feature encoding\n",
    "            categorical_features = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Location_Clean', 'Incident_Type']\n",
    "            \n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    if feature not in self.label_encoders:\n",
    "                        self.label_encoders[feature] = LabelEncoder()\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].fit_transform(features_df[feature])\n",
    "                    else:\n",
    "                        # Handle new categories\n",
    "                        known_categories = set(self.label_encoders[feature].classes_)\n",
    "                        features_df[f'{feature}_Clean'] = features_df[feature].apply(\n",
    "                            lambda x: x if x in known_categories else 'Unknown'\n",
    "                        )\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].transform(features_df[f'{feature}_Clean'])\n",
    "            \n",
    "            # Select feature columns for ML\n",
    "            feature_columns = [\n",
    "                'Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend',\n",
    "                'Asset_Incident_Count', 'Asset_Encoded'\n",
    "            ]\n",
    "            \n",
    "            # Add encoded categorical features\n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    feature_columns.append(f'{feature}_Encoded')\n",
    "            \n",
    "            # Only keep columns that exist\n",
    "            feature_columns = [col for col in feature_columns if col in features_df.columns]\n",
    "            \n",
    "            # Fill any remaining NaN values\n",
    "            features_df[feature_columns] = features_df[feature_columns].fillna(0)\n",
    "            \n",
    "            self.feature_columns = feature_columns\n",
    "            logger.info(f\"Created {len(feature_columns)} features: {feature_columns}\")\n",
    "            \n",
    "            return features_df, feature_columns\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating features: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def train_random_forest_models(self, df: pd.DataFrame, feature_columns: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Train Random Forest models for classification and regression\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with training results and metrics\n",
    "        \"\"\"\n",
    "        logger.info(\"Training Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification model (Risk Level)\n",
    "            y_class = df['Risk_Level']\n",
    "            le_risk = LabelEncoder()\n",
    "            y_class_encoded = le_risk.fit_transform(y_class)\n",
    "            \n",
    "            X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "                X, y_class_encoded, test_size=0.2, random_state=42, stratify=y_class_encoded\n",
    "            )\n",
    "            \n",
    "            # Train classification model\n",
    "            self.rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            )\n",
    "            \n",
    "            self.rf_classifier.fit(X_train_class, y_train_class)\n",
    "            y_pred_class = self.rf_classifier.predict(X_test_class)\n",
    "            \n",
    "            class_accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "            \n",
    "            # Regression model (Risk Score)\n",
    "            # Create risk scores based on priority and other factors\n",
    "            df['Risk_Score'] = df['Priority_Num'].map({1: 2.0, 2: 1.5, 3: 1.0, 4: 0.5})\n",
    "            df['Risk_Score'] += df['Asset_Incident_Count'] * 0.1  # Add volume factor\n",
    "            \n",
    "            y_reg = df['Risk_Score']\n",
    "            X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "                X, y_reg, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train regression model\n",
    "            self.rf_regressor = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            self.rf_regressor.fit(X_train_reg, y_train_reg)\n",
    "            y_pred_reg = self.rf_regressor.predict(X_test_reg)\n",
    "            \n",
    "            reg_mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "            \n",
    "            # Feature importance\n",
    "            feature_importance = dict(zip(feature_columns, self.rf_classifier.feature_importances_))\n",
    "            self.feature_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "            \n",
    "            results = {\n",
    "                'classification_accuracy': class_accuracy,\n",
    "                'regression_mae': reg_mae,\n",
    "                'feature_importance': self.feature_importance,\n",
    "                'risk_label_encoder': le_risk,\n",
    "                'n_samples': len(df),\n",
    "                'n_features': len(feature_columns)\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Model training completed:\")\n",
    "            logger.info(f\"- Classification accuracy: {class_accuracy:.3f}\")\n",
    "            logger.info(f\"- Regression MAE: {reg_mae:.3f}\")\n",
    "            logger.info(f\"- Top 3 features: {list(self.feature_importance.keys())[:3]}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training models: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def make_predictions(self, df: pd.DataFrame, feature_columns: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with predictions added\n",
    "        \"\"\"\n",
    "        logger.info(\"Making predictions with Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            if self.rf_classifier is None or self.rf_regressor is None:\n",
    "                raise ValueError(\"Models not trained yet. Call train_random_forest_models first.\")\n",
    "            \n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification predictions\n",
    "            risk_pred_encoded = self.rf_classifier.predict(X)\n",
    "            risk_pred_proba = self.rf_classifier.predict_proba(X)\n",
    "            \n",
    "            # Get class labels\n",
    "            risk_classes = self.rf_classifier.classes_\n",
    "            \n",
    "            # Convert back to labels\n",
    "            df['Predicted_Risk_Level'] = risk_pred_encoded\n",
    "            df['Risk_Level_Confidence'] = np.max(risk_pred_proba, axis=1)\n",
    "            \n",
    "            # Regression predictions\n",
    "            df['Predicted_Risk_Score'] = self.rf_regressor.predict(X)\n",
    "            \n",
    "            # Add recommendations based on predictions\n",
    "            df['Recommendation'] = df.apply(self._generate_recommendation, axis=1)\n",
    "            \n",
    "            # Add prediction timestamp\n",
    "            df['Prediction_Timestamp'] = datetime.now()\n",
    "            \n",
    "            logger.info(f\"Predictions completed for {len(df)} records\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error making predictions: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_recommendation(self, row) -> str:\n",
    "        \"\"\"Generate recommendation based on predictions\"\"\"\n",
    "        risk_score = row.get('Predicted_Risk_Score', 0)\n",
    "        risk_level = row.get('Predicted_Risk_Level', 0)\n",
    "        \n",
    "        if risk_score >= 2.0 or risk_level == 2:  # High risk\n",
    "            return \"Immediate monitoring and proactive maintenance required\"\n",
    "        elif risk_score >= 1.5 or risk_level == 1:  # Medium risk\n",
    "            return \"Enhanced monitoring and scheduled maintenance recommended\"\n",
    "        else:  # Low risk\n",
    "            return \"Standard monitoring sufficient\"\n",
    "    \n",
    "    def save_predictions_to_databricks(self, df: pd.DataFrame, target_table: str, mode: str = \"overwrite\"):\n",
    "        \"\"\"\n",
    "        Save predictions to Databricks table\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with predictions\n",
    "            target_table: Target table name (e.g., 'default.incident_predictions')\n",
    "            mode: Write mode ('overwrite', 'append')\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving predictions to Databricks table: {target_table}\")\n",
    "        \n",
    "        try:\n",
    "            # Select relevant columns for output\n",
    "            output_columns = [\n",
    "                'Asset_Name', 'Category', 'Priority', 'Location_Clean',\n",
    "                'Predicted_Risk_Level', 'Predicted_Risk_Score', 'Risk_Level_Confidence',\n",
    "                'Recommendation', 'Prediction_Timestamp'\n",
    "            ]\n",
    "            \n",
    "            # Add original identifier columns if available\n",
    "            id_columns = ['Asset_Number', 'Incident_Number']\n",
    "            for col in id_columns:\n",
    "                if col in df.columns:\n",
    "                    output_columns.insert(0, col)\n",
    "            \n",
    "            # Filter to existing columns\n",
    "            available_columns = [col for col in output_columns if col in df.columns]\n",
    "            output_df = df[available_columns].copy()\n",
    "            \n",
    "            # Convert to Spark DataFrame\n",
    "            spark_df = self.spark.createDataFrame(output_df)\n",
    "            \n",
    "            # Write to Databricks table\n",
    "            spark_df.write.mode(mode).saveAsTable(target_table)\n",
    "            \n",
    "            logger.info(f\"Successfully saved {len(output_df)} predictions to {target_table}\")\n",
    "            \n",
    "            # Log sample of results\n",
    "            logger.info(\"Sample predictions:\")\n",
    "            sample_df = output_df.head(5)\n",
    "            for _, row in sample_df.iterrows():\n",
    "                logger.info(f\"Asset: {row.get('Asset_Name', 'N/A')}, \"\n",
    "                          f\"Risk Score: {row.get('Predicted_Risk_Score', 0):.2f}, \"\n",
    "                          f\"Level: {row.get('Predicted_Risk_Level', 'N/A')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving to Databricks: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def run_full_pipeline(self, source_table: str, target_table: str, retrain: bool = True):\n",
    "        \"\"\"\n",
    "        Run the complete ML pipeline\n",
    "        \n",
    "        Args:\n",
    "            source_table: Source table with incident data\n",
    "            target_table: Target table for predictions\n",
    "            retrain: Whether to retrain models\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting full Random Forest prediction pipeline\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Read data\n",
    "            raw_df = self.read_incident_data(source_table)\n",
    "            \n",
    "            # Step 2: Clean and prepare data\n",
    "            clean_df = self.clean_and_prepare_data(raw_df)\n",
    "            \n",
    "            # Step 3: Create features\n",
    "            features_df, feature_columns = self.create_features(clean_df)\n",
    "            \n",
    "            # Step 4: Train models (if needed)\n",
    "            if retrain:\n",
    "                training_results = self.train_random_forest_models(features_df, feature_columns)\n",
    "                logger.info(f\"Training results: {training_results}\")\n",
    "            \n",
    "            # Step 5: Make predictions\n",
    "            predictions_df = self.make_predictions(features_df, feature_columns)\n",
    "            \n",
    "            # Step 6: Save to Databricks\n",
    "            self.save_predictions_to_databricks(predictions_df, target_table)\n",
    "            \n",
    "            # Step 7: Generate summary report\n",
    "            self._generate_summary_report(predictions_df)\n",
    "            \n",
    "            logger.info(\"Pipeline completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_summary_report(self, df: pd.DataFrame):\n",
    "        \"\"\"Generate summary report of predictions\"\"\"\n",
    "        logger.info(\"=== PREDICTION SUMMARY REPORT ===\")\n",
    "        \n",
    "        try:\n",
    "            total_assets = df['Asset_Name'].nunique()\n",
    "            total_predictions = len(df)\n",
    "            \n",
    "            # Risk level distribution\n",
    "            if 'Predicted_Risk_Level' in df.columns:\n",
    "                risk_dist = df['Predicted_Risk_Level'].value_counts()\n",
    "                logger.info(f\"Risk Level Distribution: {dict(risk_dist)}\")\n",
    "            \n",
    "            # Top risk assets\n",
    "            if 'Predicted_Risk_Score' in df.columns:\n",
    "                top_risk = df.nlargest(5, 'Predicted_Risk_Score')[['Asset_Name', 'Predicted_Risk_Score']]\n",
    "                logger.info(\"Top 5 Risk Assets:\")\n",
    "                for _, row in top_risk.iterrows():\n",
    "                    logger.info(f\"  - {row['Asset_Name']}: {row['Predicted_Risk_Score']:.2f}\")\n",
    "            \n",
    "            # Feature importance\n",
    "            if self.feature_importance:\n",
    "                logger.info(\"Top 5 Feature Importance:\")\n",
    "                for feature, importance in list(self.feature_importance.items())[:5]:\n",
    "                    logger.info(f\"  - {feature}: {importance:.3f}\")\n",
    "            \n",
    "            logger.info(f\"Total assets analyzed: {total_assets}\")\n",
    "            logger.info(f\"Total predictions made: {total_predictions}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    SOURCE_TABLE = \"sd_bdc_demo.default.service_now_only\"  # Replace with your table name\n",
    "    TARGET_TABLE = \"sd_bdc_demo.default.service_now_rf_predictions\"\n",
    "    \n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DatabricksRandomForestPredictor()\n",
    "        \n",
    "        # Run full pipeline\n",
    "        predictor.run_full_pipeline(\n",
    "            source_table=SOURCE_TABLE,\n",
    "            target_table=TARGET_TABLE,\n",
    "            retrain=True\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Random Forest prediction pipeline completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74ab08c-71ff-4334-a508-baba50e20033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 23:26:09,134 - INFO - Databricks Random Forest Predictor initialized\n2025-06-12 23:26:09,135 - INFO - Starting full Random Forest prediction pipeline\n2025-06-12 23:26:09,136 - INFO - Reading data from table: sd_bdc_demo.default.service_now_only\n2025-06-12 23:26:10,028 - INFO - Loaded 111 rows, 20 columns from sd_bdc_demo.default.service_now_only\n2025-06-12 23:26:10,030 - INFO - Starting data cleaning and preparation\n2025-06-12 23:26:10,418 - INFO - Data cleaning completed. Shape: (111, 29)\n2025-06-12 23:26:10,420 - INFO - Risk level distribution:\nLow       67\nHigh      37\nMedium     7\nName: Risk_Level, dtype: int64\n2025-06-12 23:26:10,422 - INFO - Creating features for Random Forest model\n2025-06-12 23:26:10,432 - INFO - Created 13 features: ['Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend', 'Asset_Incident_Count', 'Asset_Encoded', 'Category_Encoded', 'Subcategory_Encoded', 'Status_Encoded', 'Assigned_Group_Encoded', 'Location_Clean_Encoded', 'Incident_Type_Encoded']\n2025-06-12 23:26:10,434 - INFO - Training Random Forest models\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\n2025-06-12 23:26:26,329 - INFO - Error while sending or receiving.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n2025-06-12 23:26:26,330 - INFO - Closing down clientserver connection\n2025-06-12 23:26:26,333 - INFO - Exception while sending command.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 530, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while sending\n2025-06-12 23:26:26,342 - INFO - Closing down clientserver connection\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\n2025-06-12 23:26:53,769 - INFO - Error while sending or receiving.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n2025-06-12 23:26:53,770 - INFO - Closing down clientserver connection\n2025-06-12 23:26:53,771 - INFO - Exception while sending command.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 530, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while sending\n2025-06-12 23:26:53,865 - INFO - Closing down clientserver connection\n2025-06-12 23:26:54,086 - INFO - Model training completed:\n2025-06-12 23:26:54,087 - INFO - - Classification accuracy: 0.9565\n2025-06-12 23:26:54,088 - INFO - - Regression R²: 0.7830 (78.30%)\n2025-06-12 23:26:54,088 - INFO - - Regression MSE: 0.192798\n2025-06-12 23:26:54,089 - INFO - - Regression RMSE: 0.4391\n2025-06-12 23:26:54,090 - INFO - - Regression MAE: 0.3633\n2025-06-12 23:26:54,090 - INFO - - Cross-validation R² (mean±std): 0.5898±0.0824\n2025-06-12 23:26:54,091 - INFO - - Mean Absolute Percentage Error: 23.44%\n2025-06-12 23:26:54,091 - INFO - - Explained Variance: 0.7909\n2025-06-12 23:26:54,092 - INFO - - Top 3 features: ['Priority_Num', 'Category_Encoded', 'Asset_Incident_Count']\n2025-06-12 23:26:54,100 - INFO - Training results: {'classification_accuracy': 0.9565217391304348, 'regression_mse': 0.19279825659837393, 'regression_rmse': 0.4390879827533133, 'regression_mae': 0.36331281395854054, 'regression_r2': 0.7829665982348297, 'regression_explained_variance': 0.7908802677139909, 'regression_mape': 23.443231313917273, 'cv_r2_mean': 0.589838944050805, 'cv_r2_std': 0.08237502073601403, 'feature_importance': {'Priority_Num': 0.35249947369671075, 'Category_Encoded': 0.10496577873483534, 'Asset_Incident_Count': 0.09059702541180577, 'Incident_Type_Encoded': 0.0674771491695897, 'Subcategory_Encoded': 0.06472263085590493, 'Asset_Encoded': 0.06268476546723169, 'Assigned_Group_Encoded': 0.058541818209804766, 'Location_Clean_Encoded': 0.05329450473023947, 'Day_of_Month': 0.04272740964277203, 'Hour_of_Day': 0.03983904577284435, 'Status_Encoded': 0.03206571660490323, 'Day_of_Week': 0.02719461657545238, 'Is_Weekend': 0.0033900651279056082}, 'risk_label_encoder': LabelEncoder(), 'n_samples': 111, 'n_features': 13, 'target_mean': 2.157733821457327, 'target_std': 0.9055486371830831}\n2025-06-12 23:26:54,103 - INFO - Making predictions with Random Forest models\n2025-06-12 23:26:54,151 - INFO - Predictions completed for 111 records\n2025-06-12 23:26:54,151 - INFO - Saving predictions to Databricks table: sd_bdc_demo.default.service_now_rf_predictions\n2025-06-12 23:26:56,182 - INFO - Successfully saved 111 predictions to sd_bdc_demo.default.service_now_rf_predictions\n2025-06-12 23:26:56,183 - INFO - Sample predictions:\n2025-06-12 23:26:56,186 - INFO - Asset: Access Control System, Risk Score: 1.86, Level: 1\n2025-06-12 23:26:56,186 - INFO - Asset: HVAC System, Risk Score: 3.14, Level: 0\n2025-06-12 23:26:56,187 - INFO - Asset: Canon ImageRunner, Risk Score: 1.01, Level: 1\n2025-06-12 23:26:56,188 - INFO - Asset: Cisco IP Phone, Risk Score: 1.33, Level: 1\n2025-06-12 23:26:56,191 - INFO - Asset: Cisco Switch, Risk Score: 3.05, Level: 0\n2025-06-12 23:26:56,191 - INFO - === COMPREHENSIVE PREDICTION SUMMARY REPORT ===\n2025-06-12 23:26:56,193 - INFO - Risk Level Distribution: {1: 69, 0: 37, 2: 5}\n2025-06-12 23:26:56,196 - INFO - Top 5 Risk Assets:\n2025-06-12 23:26:56,198 - INFO -   - Finance App Server: 3.953\n2025-06-12 23:26:56,198 - INFO -   - Identity Provider: 3.949\n2025-06-12 23:26:56,199 - INFO -   - SQL Server: 3.790\n2025-06-12 23:26:56,200 - INFO -   - SQL Server: 3.653\n2025-06-12 23:26:56,200 - INFO -   - Domain Controller: 3.591\n2025-06-12 23:26:56,203 - INFO - Risk Score Statistics:\n2025-06-12 23:26:56,204 - INFO -   - Mean: 2.153\n2025-06-12 23:26:56,205 - INFO -   - Std Dev: 0.715\n2025-06-12 23:26:56,205 - INFO -   - Min: 0.816\n2025-06-12 23:26:56,206 - INFO -   - Max: 3.953\n2025-06-12 23:26:56,207 - INFO - Top 5 Feature Importance:\n2025-06-12 23:26:56,207 - INFO -   - Priority_Num: 0.3525 (35.25%)\n2025-06-12 23:26:56,208 - INFO -   - Category_Encoded: 0.1050 (10.50%)\n2025-06-12 23:26:56,217 - INFO -   - Asset_Incident_Count: 0.0906 (9.06%)\n2025-06-12 23:26:56,218 - INFO -   - Incident_Type_Encoded: 0.0675 (6.75%)\n2025-06-12 23:26:56,275 - INFO -   - Subcategory_Encoded: 0.0647 (6.47%)\n2025-06-12 23:26:56,276 - INFO - === MODEL PERFORMANCE METRICS ===\n2025-06-12 23:26:56,277 - INFO - R-squared (R²): 0.7830 (78.30%)\n2025-06-12 23:26:56,278 - INFO - Mean Squared Error (MSE): 0.192798\n2025-06-12 23:26:56,279 - INFO - Root Mean Squared Error (RMSE): 0.4391\n2025-06-12 23:26:56,280 - INFO - Mean Absolute Error (MAE): 0.3633\n2025-06-12 23:26:56,281 - INFO - Mean Absolute Percentage Error (MAPE): 23.44%\n2025-06-12 23:26:56,282 - INFO - Cross-validation R²: 0.5898±0.0824\n2025-06-12 23:26:56,283 - INFO - Classification Accuracy: 0.9565\n2025-06-12 23:26:56,284 - INFO - ✅ GOOD model performance (R² > 0.7)\n2025-06-12 23:26:56,285 - INFO - The model explains 78.3% of the variance in risk scores\n2025-06-12 23:26:56,286 - INFO - \nTotal assets analyzed: 59\n2025-06-12 23:26:56,301 - INFO - Total predictions made: 111\n2025-06-12 23:26:56,302 - INFO - === END REPORT ===\n2025-06-12 23:26:56,302 - INFO - Pipeline completed successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest prediction pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Databricks Random Forest Incident Prediction System\n",
    "==================================================\n",
    "\n",
    "This program reads incident data from a Databricks table, performs Random Forest\n",
    "prediction for asset risk scoring, and writes results back to Databricks.\n",
    "\n",
    "Requirements:\n",
    "- databricks-connect or running in Databricks environment\n",
    "- pandas, scikit-learn, numpy\n",
    "- Access to source and target Databricks tables\n",
    "\n",
    "Author: ML Prediction System\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Databricks/Spark imports\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, regexp_extract, to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, TimestampType\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, classification_report, mean_absolute_error, \n",
    "                           mean_squared_error, r2_score, explained_variance_score)\n",
    "import joblib\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabricksRandomForestPredictor:\n",
    "    \"\"\"\n",
    "    Random Forest predictor for IT incident risk analysis using Databricks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, spark_session: Optional[SparkSession] = None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with Spark session\n",
    "        \n",
    "        Args:\n",
    "            spark_session: Optional SparkSession, creates new one if None\n",
    "        \"\"\"\n",
    "        self.spark = spark_session or SparkSession.builder.appName(\"IncidentRiskPredictor\").getOrCreate()\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.rf_classifier = None\n",
    "        self.rf_regressor = None\n",
    "        self.feature_columns = []\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "        logger.info(\"Databricks Random Forest Predictor initialized\")\n",
    "    \n",
    "    def read_incident_data(self, table_name: str) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Read incident data from Databricks table\n",
    "        \n",
    "        Args:\n",
    "            table_name: Name of the Databricks table (e.g., 'default.incidents')\n",
    "            \n",
    "        Returns:\n",
    "            Spark DataFrame with incident data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Reading data from table: {table_name}\")\n",
    "            \n",
    "            # Read from Databricks table\n",
    "            df = self.spark.table(table_name)\n",
    "            \n",
    "            # Log data info\n",
    "            row_count = df.count()\n",
    "            col_count = len(df.columns)\n",
    "            logger.info(f\"Loaded {row_count} rows, {col_count} columns from {table_name}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading from table {table_name}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_and_prepare_data(self, df: DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clean and prepare incident data for ML processing\n",
    "        \n",
    "        Args:\n",
    "            df: Raw Spark DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Cleaned pandas DataFrame ready for ML\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting data cleaning and preparation\")\n",
    "        \n",
    "        try:\n",
    "            # Convert to pandas for easier processing\n",
    "            pdf = df.toPandas()\n",
    "            \n",
    "            # Clean column names (remove spaces, special characters)\n",
    "            pdf.columns = [col.strip().replace(' ', '_').replace('/', '_') for col in pdf.columns]\n",
    "            \n",
    "            # Parse dates\n",
    "            date_columns = ['Created_Date', 'Last_Modified', 'Resolved_Date', 'SLA_Due']\n",
    "            for col in date_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pd.to_datetime(pdf[col], errors='coerce')\n",
    "            \n",
    "            # Extract priority numbers\n",
    "            if 'Priority' in pdf.columns:\n",
    "                pdf['Priority_Num'] = pdf['Priority'].str.extract(r'(\\d+)').astype(float)\n",
    "                pdf['Priority_Num'] = pdf['Priority_Num'].fillna(3)  # Default to moderate\n",
    "            \n",
    "            # Clean asset names\n",
    "            if 'CI' in pdf.columns:\n",
    "                pdf['Asset_Name'] = pdf['CI'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Clean locations\n",
    "            if 'Location' in pdf.columns:\n",
    "                pdf['Location_Clean'] = pdf['Location'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Calculate resolution times (hours)\n",
    "            if 'Created_Date' in pdf.columns and 'Resolved_Date' in pdf.columns:\n",
    "                pdf['Resolution_Hours'] = (\n",
    "                    pdf['Resolved_Date'] - pdf['Created_Date']\n",
    "                ).dt.total_seconds() / 3600\n",
    "                pdf['Resolution_Hours'] = pdf['Resolution_Hours'].fillna(0)\n",
    "            \n",
    "            # Create time-based features\n",
    "            if 'Created_Date' in pdf.columns:\n",
    "                pdf['Day_of_Week'] = pdf['Created_Date'].dt.dayofweek\n",
    "                pdf['Hour_of_Day'] = pdf['Created_Date'].dt.hour\n",
    "                pdf['Day_of_Month'] = pdf['Created_Date'].dt.day\n",
    "                pdf['Is_Weekend'] = pdf['Day_of_Week'].isin([5, 6]).astype(int)\n",
    "            \n",
    "            # Create risk labels based on priority and resolution time\n",
    "            pdf['Risk_Level'] = 'Low'\n",
    "            if 'Priority_Num' in pdf.columns:\n",
    "                pdf.loc[pdf['Priority_Num'] == 1, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[pdf['Priority_Num'] == 2, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[(pdf['Priority_Num'] == 3) & (pdf.get('Resolution_Hours', 0) > 24), 'Risk_Level'] = 'Medium'\n",
    "            \n",
    "            # Fill missing values\n",
    "            categorical_columns = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Incident_Type']\n",
    "            for col in categorical_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pdf[col].fillna('Unknown')\n",
    "            \n",
    "            logger.info(f\"Data cleaning completed. Shape: {pdf.shape}\")\n",
    "            logger.info(f\"Risk level distribution:\\n{pdf['Risk_Level'].value_counts()}\")\n",
    "            \n",
    "            return pdf\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in data cleaning: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        \"\"\"\n",
    "        Create features for Random Forest model\n",
    "        \n",
    "        Args:\n",
    "            df: Cleaned pandas DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (feature DataFrame, list of feature column names)\n",
    "        \"\"\"\n",
    "        logger.info(\"Creating features for Random Forest model\")\n",
    "        \n",
    "        try:\n",
    "            features_df = df.copy()\n",
    "            \n",
    "            # Asset-based features\n",
    "            if 'Asset_Name' in df.columns:\n",
    "                # Count incidents per asset\n",
    "                asset_counts = df['Asset_Name'].value_counts()\n",
    "                features_df['Asset_Incident_Count'] = features_df['Asset_Name'].map(asset_counts)\n",
    "                \n",
    "                # Encode asset names\n",
    "                if 'Asset_Name' not in self.label_encoders:\n",
    "                    self.label_encoders['Asset_Name'] = LabelEncoder()\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].fit_transform(features_df['Asset_Name'])\n",
    "                else:\n",
    "                    # Handle new assets not seen during training\n",
    "                    known_assets = set(self.label_encoders['Asset_Name'].classes_)\n",
    "                    features_df['Asset_Name_Clean'] = features_df['Asset_Name'].apply(\n",
    "                        lambda x: x if x in known_assets else 'Unknown'\n",
    "                    )\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].transform(features_df['Asset_Name_Clean'])\n",
    "            \n",
    "            # Categorical feature encoding\n",
    "            categorical_features = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Location_Clean', 'Incident_Type']\n",
    "            \n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    if feature not in self.label_encoders:\n",
    "                        self.label_encoders[feature] = LabelEncoder()\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].fit_transform(features_df[feature])\n",
    "                    else:\n",
    "                        # Handle new categories\n",
    "                        known_categories = set(self.label_encoders[feature].classes_)\n",
    "                        features_df[f'{feature}_Clean'] = features_df[feature].apply(\n",
    "                            lambda x: x if x in known_categories else 'Unknown'\n",
    "                        )\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].transform(features_df[f'{feature}_Clean'])\n",
    "            \n",
    "            # Select feature columns for ML\n",
    "            feature_columns = [\n",
    "                'Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend',\n",
    "                'Asset_Incident_Count', 'Asset_Encoded'\n",
    "            ]\n",
    "            \n",
    "            # Add encoded categorical features\n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    feature_columns.append(f'{feature}_Encoded')\n",
    "            \n",
    "            # Only keep columns that exist\n",
    "            feature_columns = [col for col in feature_columns if col in features_df.columns]\n",
    "            \n",
    "            # Fill any remaining NaN values\n",
    "            features_df[feature_columns] = features_df[feature_columns].fillna(0)\n",
    "            \n",
    "            self.feature_columns = feature_columns\n",
    "            logger.info(f\"Created {len(feature_columns)} features: {feature_columns}\")\n",
    "            \n",
    "            return features_df, feature_columns\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating features: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def train_random_forest_models(self, df: pd.DataFrame, feature_columns: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Train Random Forest models for classification and regression\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with training results and metrics including MSE and R²\n",
    "        \"\"\"\n",
    "        logger.info(\"Training Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification model (Risk Level)\n",
    "            y_class = df['Risk_Level']\n",
    "            le_risk = LabelEncoder()\n",
    "            y_class_encoded = le_risk.fit_transform(y_class)\n",
    "            \n",
    "            X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "                X, y_class_encoded, test_size=0.2, random_state=42, stratify=y_class_encoded\n",
    "            )\n",
    "            \n",
    "            # Train classification model\n",
    "            self.rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            )\n",
    "            \n",
    "            self.rf_classifier.fit(X_train_class, y_train_class)\n",
    "            y_pred_class = self.rf_classifier.predict(X_test_class)\n",
    "            \n",
    "            class_accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "            \n",
    "            # Regression model (Risk Score) - Enhanced for better R² calculation\n",
    "            # Create more sophisticated risk scores\n",
    "            df['Risk_Score'] = 0.0\n",
    "            \n",
    "            # Base score from priority (primary factor)\n",
    "            priority_scores = {1: 3.0, 2: 2.0, 3: 1.0, 4: 0.5}\n",
    "            df['Risk_Score'] += df['Priority_Num'].map(priority_scores).fillna(1.0)\n",
    "            \n",
    "            # Add incident volume factor (normalized)\n",
    "            max_incidents = df['Asset_Incident_Count'].max() if 'Asset_Incident_Count' in df.columns else 1\n",
    "            if max_incidents > 0:\n",
    "                df['Risk_Score'] += (df.get('Asset_Incident_Count', 0) / max_incidents) * 1.5\n",
    "            \n",
    "            # Add resolution time factor\n",
    "            if 'Resolution_Hours' in df.columns:\n",
    "                # Normalize resolution hours (cap at 48 hours)\n",
    "                normalized_hours = np.clip(df['Resolution_Hours'] / 48.0, 0, 1)\n",
    "                df['Risk_Score'] += normalized_hours * 0.5\n",
    "            \n",
    "            # Add weekend/time factor\n",
    "            if 'Is_Weekend' in df.columns:\n",
    "                df['Risk_Score'] += df['Is_Weekend'] * 0.2  # Weekend incidents slightly riskier\n",
    "            \n",
    "            # Add category-based risk multiplier\n",
    "            if 'Category' in df.columns:\n",
    "                high_risk_categories = ['Security', 'Infrastructure', 'Network']\n",
    "                df['Category_Risk_Multiplier'] = df['Category'].apply(\n",
    "                    lambda x: 1.2 if x in high_risk_categories else 1.0\n",
    "                )\n",
    "                df['Risk_Score'] *= df['Category_Risk_Multiplier']\n",
    "            \n",
    "            y_reg = df['Risk_Score']\n",
    "            X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "                X, y_reg, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train regression model with optimized parameters\n",
    "            self.rf_regressor = RandomForestRegressor(\n",
    "                n_estimators=150,\n",
    "                max_depth=12,\n",
    "                min_samples_split=3,\n",
    "                min_samples_leaf=1,\n",
    "                max_features='sqrt',\n",
    "                random_state=42,\n",
    "                n_jobs=-1  # Use all CPU cores\n",
    "            )\n",
    "            \n",
    "            self.rf_regressor.fit(X_train_reg, y_train_reg)\n",
    "            y_pred_reg = self.rf_regressor.predict(X_test_reg)\n",
    "            \n",
    "            # Calculate comprehensive regression metrics\n",
    "            reg_mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "            reg_rmse = np.sqrt(reg_mse)\n",
    "            reg_mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "            reg_r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "            reg_explained_var = explained_variance_score(y_test_reg, y_pred_reg)\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            y_mean = np.mean(y_test_reg)\n",
    "            reg_mape = np.mean(np.abs((y_test_reg - y_pred_reg) / y_test_reg)) * 100  # Mean Absolute Percentage Error\n",
    "            \n",
    "            # Feature importance\n",
    "            feature_importance = dict(zip(feature_columns, self.rf_regressor.feature_importances_))\n",
    "            self.feature_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "            \n",
    "            # Cross-validation score for more robust R²\n",
    "            from sklearn.model_selection import cross_val_score\n",
    "            cv_r2_scores = cross_val_score(self.rf_regressor, X, y_reg, cv=5, scoring='r2')\n",
    "            cv_r2_mean = np.mean(cv_r2_scores)\n",
    "            cv_r2_std = np.std(cv_r2_scores)\n",
    "            \n",
    "            results = {\n",
    "                # Classification metrics\n",
    "                'classification_accuracy': class_accuracy,\n",
    "                \n",
    "                # Regression metrics\n",
    "                'regression_mse': reg_mse,\n",
    "                'regression_rmse': reg_rmse,\n",
    "                'regression_mae': reg_mae,\n",
    "                'regression_r2': reg_r2,\n",
    "                'regression_explained_variance': reg_explained_var,\n",
    "                'regression_mape': reg_mape,\n",
    "                \n",
    "                # Cross-validation metrics\n",
    "                'cv_r2_mean': cv_r2_mean,\n",
    "                'cv_r2_std': cv_r2_std,\n",
    "                \n",
    "                # Model details\n",
    "                'feature_importance': self.feature_importance,\n",
    "                'risk_label_encoder': le_risk,\n",
    "                'n_samples': len(df),\n",
    "                'n_features': len(feature_columns),\n",
    "                'target_mean': y_mean,\n",
    "                'target_std': np.std(y_reg)\n",
    "            }\n",
    "            \n",
    "            # Log detailed metrics\n",
    "            logger.info(f\"Model training completed:\")\n",
    "            logger.info(f\"- Classification accuracy: {class_accuracy:.4f}\")\n",
    "            logger.info(f\"- Regression R²: {reg_r2:.4f} ({reg_r2*100:.2f}%)\")\n",
    "            logger.info(f\"- Regression MSE: {reg_mse:.6f}\")\n",
    "            logger.info(f\"- Regression RMSE: {reg_rmse:.4f}\")\n",
    "            logger.info(f\"- Regression MAE: {reg_mae:.4f}\")\n",
    "            logger.info(f\"- Cross-validation R² (mean±std): {cv_r2_mean:.4f}±{cv_r2_std:.4f}\")\n",
    "            logger.info(f\"- Mean Absolute Percentage Error: {reg_mape:.2f}%\")\n",
    "            logger.info(f\"- Explained Variance: {reg_explained_var:.4f}\")\n",
    "            logger.info(f\"- Top 3 features: {list(self.feature_importance.keys())[:3]}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training models: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def make_predictions(self, df: pd.DataFrame, feature_columns: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with predictions added\n",
    "        \"\"\"\n",
    "        logger.info(\"Making predictions with Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            if self.rf_classifier is None or self.rf_regressor is None:\n",
    "                raise ValueError(\"Models not trained yet. Call train_random_forest_models first.\")\n",
    "            \n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification predictions\n",
    "            risk_pred_encoded = self.rf_classifier.predict(X)\n",
    "            risk_pred_proba = self.rf_classifier.predict_proba(X)\n",
    "            \n",
    "            # Get class labels\n",
    "            risk_classes = self.rf_classifier.classes_\n",
    "            \n",
    "            # Convert back to labels\n",
    "            df['Predicted_Risk_Level'] = risk_pred_encoded\n",
    "            df['Risk_Level_Confidence'] = np.max(risk_pred_proba, axis=1)\n",
    "            \n",
    "            # Regression predictions\n",
    "            df['Predicted_Risk_Score'] = self.rf_regressor.predict(X)\n",
    "            \n",
    "            # Add recommendations based on predictions\n",
    "            df['Recommendation'] = df.apply(self._generate_recommendation, axis=1)\n",
    "            \n",
    "            # Add prediction timestamp\n",
    "            df['Prediction_Timestamp'] = datetime.now()\n",
    "            \n",
    "            logger.info(f\"Predictions completed for {len(df)} records\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error making predictions: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_recommendation(self, row) -> str:\n",
    "        \"\"\"Generate recommendation based on predictions\"\"\"\n",
    "        risk_score = row.get('Predicted_Risk_Score', 0)\n",
    "        risk_level = row.get('Predicted_Risk_Level', 0)\n",
    "        \n",
    "        if risk_score >= 2.0 or risk_level == 2:  # High risk\n",
    "            return \"Immediate monitoring and proactive maintenance required\"\n",
    "        elif risk_score >= 1.5 or risk_level == 1:  # Medium risk\n",
    "            return \"Enhanced monitoring and scheduled maintenance recommended\"\n",
    "        else:  # Low risk\n",
    "            return \"Standard monitoring sufficient\"\n",
    "    \n",
    "    def save_predictions_to_databricks(self, df: pd.DataFrame, target_table: str, mode: str = \"overwrite\"):\n",
    "        \"\"\"\n",
    "        Save predictions to Databricks table\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with predictions\n",
    "            target_table: Target table name (e.g., 'default.incident_predictions')\n",
    "            mode: Write mode ('overwrite', 'append')\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving predictions to Databricks table: {target_table}\")\n",
    "        \n",
    "        try:\n",
    "            # Select relevant columns for output\n",
    "            output_columns = [\n",
    "                'Asset_Name', 'Category', 'Priority', 'Location_Clean',\n",
    "                'Predicted_Risk_Level', 'Predicted_Risk_Score', 'Risk_Level_Confidence',\n",
    "                'Recommendation', 'Prediction_Timestamp'\n",
    "            ]\n",
    "            \n",
    "            # Add original identifier columns if available\n",
    "            id_columns = ['Asset_Number', 'Incident_Number']\n",
    "            for col in id_columns:\n",
    "                if col in df.columns:\n",
    "                    output_columns.insert(0, col)\n",
    "            \n",
    "            # Filter to existing columns\n",
    "            available_columns = [col for col in output_columns if col in df.columns]\n",
    "            output_df = df[available_columns].copy()\n",
    "            \n",
    "            # Convert to Spark DataFrame\n",
    "            spark_df = self.spark.createDataFrame(output_df)\n",
    "            \n",
    "            # Write to Databricks table\n",
    "            spark_df.write.mode(mode).saveAsTable(target_table)\n",
    "            \n",
    "            logger.info(f\"Successfully saved {len(output_df)} predictions to {target_table}\")\n",
    "            \n",
    "            # Log sample of results\n",
    "            logger.info(\"Sample predictions:\")\n",
    "            sample_df = output_df.head(5)\n",
    "            for _, row in sample_df.iterrows():\n",
    "                logger.info(f\"Asset: {row.get('Asset_Name', 'N/A')}, \"\n",
    "                          f\"Risk Score: {row.get('Predicted_Risk_Score', 0):.2f}, \"\n",
    "                          f\"Level: {row.get('Predicted_Risk_Level', 'N/A')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving to Databricks: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def run_full_pipeline(self, source_table: str, target_table: str, retrain: bool = True):\n",
    "        \"\"\"\n",
    "        Run the complete ML pipeline\n",
    "        \n",
    "        Args:\n",
    "            source_table: Source table with incident data\n",
    "            target_table: Target table for predictions\n",
    "            retrain: Whether to retrain models\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting full Random Forest prediction pipeline\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Read data\n",
    "            raw_df = self.read_incident_data(source_table)\n",
    "            \n",
    "            # Step 2: Clean and prepare data\n",
    "            clean_df = self.clean_and_prepare_data(raw_df)\n",
    "            \n",
    "            # Step 3: Create features\n",
    "            features_df, feature_columns = self.create_features(clean_df)\n",
    "            \n",
    "            # Step 4: Train models (if needed)\n",
    "            if retrain:\n",
    "                training_results = self.train_random_forest_models(features_df, feature_columns)\n",
    "                self._last_training_results = training_results  # Store for summary report\n",
    "                logger.info(f\"Training results: {training_results}\")\n",
    "            \n",
    "            # Step 5: Make predictions\n",
    "            predictions_df = self.make_predictions(features_df, feature_columns)\n",
    "            \n",
    "            # Step 6: Save to Databricks\n",
    "            self.save_predictions_to_databricks(predictions_df, target_table)\n",
    "            \n",
    "            # Step 7: Generate summary report\n",
    "            self._generate_summary_report(predictions_df)\n",
    "            \n",
    "            logger.info(\"Pipeline completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_summary_report(self, df: pd.DataFrame):\n",
    "        \"\"\"Generate comprehensive summary report of predictions with model metrics\"\"\"\n",
    "        logger.info(\"=== COMPREHENSIVE PREDICTION SUMMARY REPORT ===\")\n",
    "        \n",
    "        try:\n",
    "            total_assets = df['Asset_Name'].nunique()\n",
    "            total_predictions = len(df)\n",
    "            \n",
    "            # Risk level distribution\n",
    "            if 'Predicted_Risk_Level' in df.columns:\n",
    "                risk_dist = df['Predicted_Risk_Level'].value_counts()\n",
    "                logger.info(f\"Risk Level Distribution: {dict(risk_dist)}\")\n",
    "            \n",
    "            # Top risk assets\n",
    "            if 'Predicted_Risk_Score' in df.columns:\n",
    "                top_risk = df.nlargest(5, 'Predicted_Risk_Score')[['Asset_Name', 'Predicted_Risk_Score']]\n",
    "                logger.info(\"Top 5 Risk Assets:\")\n",
    "                for _, row in top_risk.iterrows():\n",
    "                    logger.info(f\"  - {row['Asset_Name']}: {row['Predicted_Risk_Score']:.3f}\")\n",
    "                \n",
    "                # Risk score statistics\n",
    "                risk_stats = df['Predicted_Risk_Score'].describe()\n",
    "                logger.info(f\"Risk Score Statistics:\")\n",
    "                logger.info(f\"  - Mean: {risk_stats['mean']:.3f}\")\n",
    "                logger.info(f\"  - Std Dev: {risk_stats['std']:.3f}\")\n",
    "                logger.info(f\"  - Min: {risk_stats['min']:.3f}\")\n",
    "                logger.info(f\"  - Max: {risk_stats['max']:.3f}\")\n",
    "            \n",
    "            # Feature importance\n",
    "            if self.feature_importance:\n",
    "                logger.info(\"Top 5 Feature Importance:\")\n",
    "                for feature, importance in list(self.feature_importance.items())[:5]:\n",
    "                    logger.info(f\"  - {feature}: {importance:.4f} ({importance*100:.2f}%)\")\n",
    "            \n",
    "            # Model performance summary\n",
    "            logger.info(\"=== MODEL PERFORMANCE METRICS ===\")\n",
    "            if hasattr(self, '_last_training_results'):\n",
    "                results = self._last_training_results\n",
    "                logger.info(f\"R-squared (R²): {results.get('regression_r2', 0):.4f} ({results.get('regression_r2', 0)*100:.2f}%)\")\n",
    "                logger.info(f\"Mean Squared Error (MSE): {results.get('regression_mse', 0):.6f}\")\n",
    "                logger.info(f\"Root Mean Squared Error (RMSE): {results.get('regression_rmse', 0):.4f}\")\n",
    "                logger.info(f\"Mean Absolute Error (MAE): {results.get('regression_mae', 0):.4f}\")\n",
    "                logger.info(f\"Mean Absolute Percentage Error (MAPE): {results.get('regression_mape', 0):.2f}%\")\n",
    "                logger.info(f\"Cross-validation R²: {results.get('cv_r2_mean', 0):.4f}±{results.get('cv_r2_std', 0):.4f}\")\n",
    "                logger.info(f\"Classification Accuracy: {results.get('classification_accuracy', 0):.4f}\")\n",
    "                \n",
    "                # Model interpretation\n",
    "                r2 = results.get('regression_r2', 0)\n",
    "                if r2 > 0.9:\n",
    "                    logger.info(\"✅ EXCELLENT model performance (R² > 0.9)\")\n",
    "                elif r2 > 0.8:\n",
    "                    logger.info(\"✅ VERY GOOD model performance (R² > 0.8)\")  \n",
    "                elif r2 > 0.7:\n",
    "                    logger.info(\"✅ GOOD model performance (R² > 0.7)\")\n",
    "                elif r2 > 0.5:\n",
    "                    logger.info(\"⚠️ MODERATE model performance (R² > 0.5)\")\n",
    "                else:\n",
    "                    logger.info(\"❌ POOR model performance (R² < 0.5)\")\n",
    "                \n",
    "                logger.info(f\"The model explains {r2*100:.1f}% of the variance in risk scores\")\n",
    "            \n",
    "            logger.info(f\"\\nTotal assets analyzed: {total_assets}\")\n",
    "            logger.info(f\"Total predictions made: {total_predictions}\")\n",
    "            logger.info(\"=== END REPORT ===\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    SOURCE_TABLE = \"sd_bdc_demo.default.service_now_only\"  # Replace with your table name\n",
    "    TARGET_TABLE = \"sd_bdc_demo.default.service_now_rf_predictions\"\n",
    "    \n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DatabricksRandomForestPredictor()\n",
    "        \n",
    "        # Run full pipeline\n",
    "        predictor.run_full_pipeline(\n",
    "            source_table=SOURCE_TABLE,\n",
    "            target_table=TARGET_TABLE,\n",
    "            retrain=True\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Random Forest prediction pipeline completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f7ea21e-37b4-4031-b587-e2fcedae7bef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 12:35:10,149 - INFO - Databricks Random Forest Predictor initialized\n2025-06-13 12:35:10,153 - INFO - Starting full Random Forest prediction pipeline with metrics tracking\n2025-06-13 12:35:10,155 - INFO - Reading data from table: sd_bdc_demo.default.service_now_only\n2025-06-13 12:35:22,575 - INFO - Loaded 111 rows, 20 columns from sd_bdc_demo.default.service_now_only\n2025-06-13 12:35:22,578 - INFO - Starting data cleaning and preparation\n2025-06-13 12:35:26,119 - INFO - Data cleaning completed. Shape: (111, 29)\n2025-06-13 12:35:26,122 - INFO - Risk level distribution:\nLow       67\nHigh      37\nMedium     7\nName: Risk_Level, dtype: int64\n2025-06-13 12:35:26,123 - INFO - Creating features for Random Forest model\n2025-06-13 12:35:26,150 - INFO - Created 13 features: ['Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend', 'Asset_Incident_Count', 'Asset_Encoded', 'Category_Encoded', 'Subcategory_Encoded', 'Status_Encoded', 'Assigned_Group_Encoded', 'Location_Clean_Encoded', 'Incident_Type_Encoded']\n2025-06-13 12:35:26,162 - INFO - Training Random Forest models\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\n2025-06-13 12:35:40,413 - INFO - Error while sending or receiving.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n2025-06-13 12:35:40,425 - INFO - Closing down clientserver connection\n2025-06-13 12:35:40,426 - INFO - Exception while sending command.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 530, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while sending\n2025-06-13 12:35:40,433 - INFO - Closing down clientserver connection\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\nIOStream.flush timed out\n2025-06-13 12:35:59,566 - INFO - Error while sending or receiving.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n2025-06-13 12:35:59,569 - INFO - Closing down clientserver connection\n2025-06-13 12:35:59,571 - INFO - Exception while sending command.\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 527, in send_command\n    self.socket.sendall(command.encode(\"utf-8\"))\nConnectionResetError: [Errno 104] Connection reset by peer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/spark/python/lib/py4j-0.10.9.8-src.zip/py4j/clientserver.py\", line 530, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while sending\n2025-06-13 12:35:59,613 - INFO - Closing down clientserver connection\n2025-06-13 12:36:00,471 - INFO - Model training completed:\n2025-06-13 12:36:00,474 - INFO - - Classification accuracy: 0.9565\n2025-06-13 12:36:00,483 - INFO - - Regression R²: 0.7830 (78.30%)\n2025-06-13 12:36:00,485 - INFO - - Regression MSE: 0.192798\n2025-06-13 12:36:00,487 - INFO - - Regression RMSE: 0.4391\n2025-06-13 12:36:00,488 - INFO - - Regression MAE: 0.3633\n2025-06-13 12:36:00,489 - INFO - - Cross-validation R² (mean±std): 0.5898±0.0824\n2025-06-13 12:36:00,492 - INFO - - Mean Absolute Percentage Error: 23.44%\n2025-06-13 12:36:00,494 - INFO - - Explained Variance: 0.7909\n2025-06-13 12:36:00,494 - INFO - - Top 3 features: ['Priority_Num', 'Category_Encoded', 'Asset_Incident_Count']\n2025-06-13 12:36:00,496 - INFO - Training completed with R²: 0.7830\n2025-06-13 12:36:00,497 - INFO - Saving model metrics to Databricks table: sd_bdc_demo.default.service_now_rf_model_performance_metrics\n2025-06-13 12:36:01,911 - INFO - Metrics table sd_bdc_demo.default.service_now_rf_model_performance_metrics already exists\n2025-06-13 12:36:06,200 - INFO - Successfully saved model metrics to sd_bdc_demo.default.service_now_rf_model_performance_metrics\n2025-06-13 12:36:06,201 - INFO - Model Run ID: rf_incident_prediction_20250613_123600\n2025-06-13 12:36:06,202 - INFO - R²: 0.7830, MSE: 0.192798\n2025-06-13 12:36:06,203 - INFO - Performance Grade: ACCEPTABLE\n2025-06-13 12:36:06,204 - INFO - Making predictions with Random Forest models\n2025-06-13 12:36:06,265 - INFO - Predictions completed for 111 records\n2025-06-13 12:36:06,266 - INFO - Saving predictions to Databricks table: sd_bdc_demo.default.service_now_rf_predictions\n2025-06-13 12:36:09,480 - INFO - Successfully saved 111 predictions to sd_bdc_demo.default.service_now_rf_predictions\n2025-06-13 12:36:09,482 - INFO - Sample predictions:\n2025-06-13 12:36:09,484 - INFO - Asset: Access Control System, Risk Score: 1.86, Level: 1\n2025-06-13 12:36:09,485 - INFO - Asset: HVAC System, Risk Score: 3.14, Level: 0\n2025-06-13 12:36:09,487 - INFO - Asset: Canon ImageRunner, Risk Score: 1.01, Level: 1\n2025-06-13 12:36:09,489 - INFO - Asset: Cisco IP Phone, Risk Score: 1.33, Level: 1\n2025-06-13 12:36:09,489 - INFO - Asset: Cisco Switch, Risk Score: 3.05, Level: 0\n2025-06-13 12:36:09,490 - INFO - === COMPREHENSIVE PREDICTION SUMMARY REPORT ===\n2025-06-13 12:36:09,502 - INFO - Risk Level Distribution: {1: 69, 0: 37, 2: 5}\n2025-06-13 12:36:09,516 - INFO - Top 5 Risk Assets:\n2025-06-13 12:36:09,518 - INFO -   - Finance App Server: 3.953\n2025-06-13 12:36:09,524 - INFO -   - Identity Provider: 3.949\n2025-06-13 12:36:09,526 - INFO -   - SQL Server: 3.790\n2025-06-13 12:36:09,529 - INFO -   - SQL Server: 3.653\n2025-06-13 12:36:09,538 - INFO -   - Domain Controller: 3.591\n2025-06-13 12:36:09,542 - INFO - Risk Score Statistics:\n2025-06-13 12:36:09,544 - INFO -   - Mean: 2.153\n2025-06-13 12:36:09,545 - INFO -   - Std Dev: 0.715\n2025-06-13 12:36:09,546 - INFO -   - Min: 0.816\n2025-06-13 12:36:09,547 - INFO -   - Max: 3.953\n2025-06-13 12:36:09,548 - INFO - Top 5 Feature Importance:\n2025-06-13 12:36:09,551 - INFO -   - Priority_Num: 0.3525 (35.25%)\n2025-06-13 12:36:09,555 - INFO -   - Category_Encoded: 0.1050 (10.50%)\n2025-06-13 12:36:09,559 - INFO -   - Asset_Incident_Count: 0.0906 (9.06%)\n2025-06-13 12:36:09,559 - INFO -   - Incident_Type_Encoded: 0.0675 (6.75%)\n2025-06-13 12:36:09,560 - INFO -   - Subcategory_Encoded: 0.0647 (6.47%)\n2025-06-13 12:36:09,561 - INFO - === MODEL PERFORMANCE METRICS ===\n2025-06-13 12:36:09,561 - INFO - R-squared (R²): 0.7830 (78.30%)\n2025-06-13 12:36:09,562 - INFO - Mean Squared Error (MSE): 0.192798\n2025-06-13 12:36:09,562 - INFO - Root Mean Squared Error (RMSE): 0.4391\n2025-06-13 12:36:09,563 - INFO - Mean Absolute Error (MAE): 0.3633\n2025-06-13 12:36:09,564 - INFO - Mean Absolute Percentage Error (MAPE): 23.44%\n2025-06-13 12:36:09,564 - INFO - Cross-validation R²: 0.5898±0.0824\n2025-06-13 12:36:09,565 - INFO - Classification Accuracy: 0.9565\n2025-06-13 12:36:09,565 - INFO - ✅ GOOD model performance (R² > 0.7)\n2025-06-13 12:36:09,565 - INFO - The model explains 78.3% of the variance in risk scores\n2025-06-13 12:36:09,566 - INFO - \nTotal assets analyzed: 59\n2025-06-13 12:36:09,566 - INFO - Total predictions made: 111\n2025-06-13 12:36:09,567 - INFO - === END REPORT ===\n2025-06-13 12:36:09,567 - INFO - Pipeline completed successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest prediction pipeline completed successfully!\n\uD83D\uDCCA Results: {'status': 'success', 'predictions_table': 'sd_bdc_demo.default.service_now_rf_predictions', 'metrics_table': 'sd_bdc_demo.default.service_now_rf_model_performance_metrics', 'records_processed': 111, 'assets_analyzed': 59, 'model_performance': {'classification_accuracy': 0.9565217391304348, 'regression_mse': 0.19279825659837393, 'regression_rmse': 0.4390879827533133, 'regression_mae': 0.36331281395854054, 'regression_r2': 0.7829665982348297, 'regression_explained_variance': 0.7908802677139908, 'regression_mape': 23.443231313917273, 'cv_r2_mean': 0.589838944050805, 'cv_r2_std': 0.08237502073601397, 'feature_importance': {'Priority_Num': 0.35249947369671075, 'Category_Encoded': 0.10496577873483534, 'Asset_Incident_Count': 0.09059702541180577, 'Incident_Type_Encoded': 0.0674771491695897, 'Subcategory_Encoded': 0.06472263085590493, 'Asset_Encoded': 0.06268476546723169, 'Assigned_Group_Encoded': 0.058541818209804766, 'Location_Clean_Encoded': 0.05329450473023947, 'Day_of_Month': 0.04272740964277203, 'Hour_of_Day': 0.03983904577284435, 'Status_Encoded': 0.03206571660490323, 'Day_of_Week': 0.02719461657545238, 'Is_Weekend': 0.0033900651279056082}, 'risk_label_encoder': LabelEncoder(), 'n_samples': 111, 'n_features': 13, 'target_mean': 2.157733821457327, 'target_std': 0.9055486371830831}}\n\uD83D\uDCC8 Predictions saved to: sd_bdc_demo.default.service_now_rf_predictions\n\uD83D\uDCCB Model metrics saved to: sd_bdc_demo.default.service_now_rf_model_performance_metrics\n\n\uD83C\uDFAF Latest Model Performance:\n   - Run ID: rf_incident_prediction_20250613_123600\n   - R²: 0.7830\n   - MSE: 0.192798\n   - Grade: ACCEPTABLE\n   - Quality Score: 100.0/100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Databricks Random Forest Incident Prediction System - FIXED VERSION\n",
    "==================================================================\n",
    "\n",
    "This program reads incident data from a Databricks table, performs Random Forest\n",
    "prediction for asset risk scoring, and writes results back to Databricks.\n",
    "\n",
    "Requirements:\n",
    "- databricks-connect or running in Databricks environment\n",
    "- pandas, scikit-learn, numpy\n",
    "- Access to source and target Databricks tables\n",
    "\n",
    "Author: ML Prediction System\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Databricks/Spark imports\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when, isnan, isnull, regexp_extract, to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, TimestampType\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, classification_report, mean_absolute_error, \n",
    "                           mean_squared_error, r2_score, explained_variance_score)\n",
    "import joblib\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DatabricksRandomForestPredictor:\n",
    "    \"\"\"\n",
    "    Random Forest predictor for IT incident risk analysis using Databricks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, spark_session: Optional[SparkSession] = None):\n",
    "        \"\"\"\n",
    "        Initialize the predictor with Spark session\n",
    "        \n",
    "        Args:\n",
    "            spark_session: Optional SparkSession, creates new one if None\n",
    "        \"\"\"\n",
    "        self.spark = spark_session or SparkSession.builder.appName(\"IncidentRiskPredictor\").getOrCreate()\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        self.rf_classifier = None\n",
    "        self.rf_regressor = None\n",
    "        self.feature_columns = []\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "        logger.info(\"Databricks Random Forest Predictor initialized\")\n",
    "    \n",
    "    def read_incident_data(self, table_name: str) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Read incident data from Databricks table\n",
    "        \n",
    "        Args:\n",
    "            table_name: Name of the Databricks table (e.g., 'default.incidents')\n",
    "            \n",
    "        Returns:\n",
    "            Spark DataFrame with incident data\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Reading data from table: {table_name}\")\n",
    "            \n",
    "            # Read from Databricks table\n",
    "            df = self.spark.table(table_name)\n",
    "            \n",
    "            # Log data info\n",
    "            row_count = df.count()\n",
    "            col_count = len(df.columns)\n",
    "            logger.info(f\"Loaded {row_count} rows, {col_count} columns from {table_name}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading from table {table_name}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_and_prepare_data(self, df: DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Clean and prepare incident data for ML processing\n",
    "        \n",
    "        Args:\n",
    "            df: Raw Spark DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Cleaned pandas DataFrame ready for ML\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting data cleaning and preparation\")\n",
    "        \n",
    "        try:\n",
    "            # Convert to pandas for easier processing\n",
    "            pdf = df.toPandas()\n",
    "            \n",
    "            # Clean column names (remove spaces, special characters)\n",
    "            pdf.columns = [col.strip().replace(' ', '_').replace('/', '_') for col in pdf.columns]\n",
    "            \n",
    "            # Parse dates\n",
    "            date_columns = ['Created_Date', 'Last_Modified', 'Resolved_Date', 'SLA_Due']\n",
    "            for col in date_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pd.to_datetime(pdf[col], errors='coerce')\n",
    "            \n",
    "            # Extract priority numbers\n",
    "            if 'Priority' in pdf.columns:\n",
    "                pdf['Priority_Num'] = pdf['Priority'].str.extract(r'(\\d+)').astype(float)\n",
    "                pdf['Priority_Num'] = pdf['Priority_Num'].fillna(3)  # Default to moderate\n",
    "            \n",
    "            # Clean asset names\n",
    "            if 'CI' in pdf.columns:\n",
    "                pdf['Asset_Name'] = pdf['CI'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Clean locations\n",
    "            if 'Location' in pdf.columns:\n",
    "                pdf['Location_Clean'] = pdf['Location'].fillna('Unknown').str.strip()\n",
    "            \n",
    "            # Calculate resolution times (hours)\n",
    "            if 'Created_Date' in pdf.columns and 'Resolved_Date' in pdf.columns:\n",
    "                pdf['Resolution_Hours'] = (\n",
    "                    pdf['Resolved_Date'] - pdf['Created_Date']\n",
    "                ).dt.total_seconds() / 3600\n",
    "                pdf['Resolution_Hours'] = pdf['Resolution_Hours'].fillna(0)\n",
    "            \n",
    "            # Create time-based features\n",
    "            if 'Created_Date' in pdf.columns:\n",
    "                pdf['Day_of_Week'] = pdf['Created_Date'].dt.dayofweek\n",
    "                pdf['Hour_of_Day'] = pdf['Created_Date'].dt.hour\n",
    "                pdf['Day_of_Month'] = pdf['Created_Date'].dt.day\n",
    "                pdf['Is_Weekend'] = pdf['Day_of_Week'].isin([5, 6]).astype(int)\n",
    "            \n",
    "            # Create risk labels based on priority and resolution time\n",
    "            pdf['Risk_Level'] = 'Low'\n",
    "            if 'Priority_Num' in pdf.columns:\n",
    "                pdf.loc[pdf['Priority_Num'] == 1, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[pdf['Priority_Num'] == 2, 'Risk_Level'] = 'High'\n",
    "                pdf.loc[(pdf['Priority_Num'] == 3) & (pdf.get('Resolution_Hours', 0) > 24), 'Risk_Level'] = 'Medium'\n",
    "            \n",
    "            # Fill missing values\n",
    "            categorical_columns = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Incident_Type']\n",
    "            for col in categorical_columns:\n",
    "                if col in pdf.columns:\n",
    "                    pdf[col] = pdf[col].fillna('Unknown')\n",
    "            \n",
    "            logger.info(f\"Data cleaning completed. Shape: {pdf.shape}\")\n",
    "            logger.info(f\"Risk level distribution:\\n{pdf['Risk_Level'].value_counts()}\")\n",
    "            \n",
    "            return pdf\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in data cleaning: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def create_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:\n",
    "        \"\"\"\n",
    "        Create features for Random Forest model\n",
    "        \n",
    "        Args:\n",
    "            df: Cleaned pandas DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (feature DataFrame, list of feature column names)\n",
    "        \"\"\"\n",
    "        logger.info(\"Creating features for Random Forest model\")\n",
    "        \n",
    "        try:\n",
    "            features_df = df.copy()\n",
    "            \n",
    "            # Asset-based features\n",
    "            if 'Asset_Name' in df.columns:\n",
    "                # Count incidents per asset\n",
    "                asset_counts = df['Asset_Name'].value_counts()\n",
    "                features_df['Asset_Incident_Count'] = features_df['Asset_Name'].map(asset_counts)\n",
    "                \n",
    "                # Encode asset names\n",
    "                if 'Asset_Name' not in self.label_encoders:\n",
    "                    self.label_encoders['Asset_Name'] = LabelEncoder()\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].fit_transform(features_df['Asset_Name'])\n",
    "                else:\n",
    "                    # Handle new assets not seen during training\n",
    "                    known_assets = set(self.label_encoders['Asset_Name'].classes_)\n",
    "                    features_df['Asset_Name_Clean'] = features_df['Asset_Name'].apply(\n",
    "                        lambda x: x if x in known_assets else 'Unknown'\n",
    "                    )\n",
    "                    features_df['Asset_Encoded'] = self.label_encoders['Asset_Name'].transform(features_df['Asset_Name_Clean'])\n",
    "            \n",
    "            # Categorical feature encoding\n",
    "            categorical_features = ['Category', 'Subcategory', 'Status', 'Assigned_Group', 'Location_Clean', 'Incident_Type']\n",
    "            \n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    if feature not in self.label_encoders:\n",
    "                        self.label_encoders[feature] = LabelEncoder()\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].fit_transform(features_df[feature])\n",
    "                    else:\n",
    "                        # Handle new categories\n",
    "                        known_categories = set(self.label_encoders[feature].classes_)\n",
    "                        features_df[f'{feature}_Clean'] = features_df[feature].apply(\n",
    "                            lambda x: x if x in known_categories else 'Unknown'\n",
    "                        )\n",
    "                        features_df[f'{feature}_Encoded'] = self.label_encoders[feature].transform(features_df[f'{feature}_Clean'])\n",
    "            \n",
    "            # Select feature columns for ML\n",
    "            feature_columns = [\n",
    "                'Priority_Num', 'Day_of_Week', 'Hour_of_Day', 'Day_of_Month', 'Is_Weekend',\n",
    "                'Asset_Incident_Count', 'Asset_Encoded'\n",
    "            ]\n",
    "            \n",
    "            # Add encoded categorical features\n",
    "            for feature in categorical_features:\n",
    "                if feature in df.columns:\n",
    "                    feature_columns.append(f'{feature}_Encoded')\n",
    "            \n",
    "            # Only keep columns that exist\n",
    "            feature_columns = [col for col in feature_columns if col in features_df.columns]\n",
    "            \n",
    "            # Fill any remaining NaN values\n",
    "            features_df[feature_columns] = features_df[feature_columns].fillna(0)\n",
    "            \n",
    "            self.feature_columns = feature_columns\n",
    "            logger.info(f\"Created {len(feature_columns)} features: {feature_columns}\")\n",
    "            \n",
    "            return features_df, feature_columns\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating features: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def train_random_forest_models(self, df: pd.DataFrame, feature_columns: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Train Random Forest models for classification and regression\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with training results and metrics including MSE and R²\n",
    "        \"\"\"\n",
    "        logger.info(\"Training Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification model (Risk Level)\n",
    "            y_class = df['Risk_Level']\n",
    "            le_risk = LabelEncoder()\n",
    "            y_class_encoded = le_risk.fit_transform(y_class)\n",
    "            \n",
    "            X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "                X, y_class_encoded, test_size=0.2, random_state=42, stratify=y_class_encoded\n",
    "            )\n",
    "            \n",
    "            # Train classification model\n",
    "            self.rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                class_weight='balanced'\n",
    "            )\n",
    "            \n",
    "            self.rf_classifier.fit(X_train_class, y_train_class)\n",
    "            y_pred_class = self.rf_classifier.predict(X_test_class)\n",
    "            \n",
    "            class_accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "            \n",
    "            # Regression model (Risk Score) - Enhanced for better R² calculation\n",
    "            # Create more sophisticated risk scores\n",
    "            df['Risk_Score'] = 0.0\n",
    "            \n",
    "            # Base score from priority (primary factor)\n",
    "            priority_scores = {1: 3.0, 2: 2.0, 3: 1.0, 4: 0.5}\n",
    "            df['Risk_Score'] += df['Priority_Num'].map(priority_scores).fillna(1.0)\n",
    "            \n",
    "            # Add incident volume factor (normalized)\n",
    "            max_incidents = df['Asset_Incident_Count'].max() if 'Asset_Incident_Count' in df.columns else 1\n",
    "            if max_incidents > 0:\n",
    "                df['Risk_Score'] += (df.get('Asset_Incident_Count', 0) / max_incidents) * 1.5\n",
    "            \n",
    "            # Add resolution time factor\n",
    "            if 'Resolution_Hours' in df.columns:\n",
    "                # Normalize resolution hours (cap at 48 hours)\n",
    "                normalized_hours = np.clip(df['Resolution_Hours'] / 48.0, 0, 1)\n",
    "                df['Risk_Score'] += normalized_hours * 0.5\n",
    "            \n",
    "            # Add weekend/time factor\n",
    "            if 'Is_Weekend' in df.columns:\n",
    "                df['Risk_Score'] += df['Is_Weekend'] * 0.2  # Weekend incidents slightly riskier\n",
    "            \n",
    "            # Add category-based risk multiplier\n",
    "            if 'Category' in df.columns:\n",
    "                high_risk_categories = ['Security', 'Infrastructure', 'Network']\n",
    "                df['Category_Risk_Multiplier'] = df['Category'].apply(\n",
    "                    lambda x: 1.2 if x in high_risk_categories else 1.0\n",
    "                )\n",
    "                df['Risk_Score'] *= df['Category_Risk_Multiplier']\n",
    "            \n",
    "            y_reg = df['Risk_Score']\n",
    "            X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "                X, y_reg, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Train regression model with optimized parameters\n",
    "            self.rf_regressor = RandomForestRegressor(\n",
    "                n_estimators=150,\n",
    "                max_depth=12,\n",
    "                min_samples_split=3,\n",
    "                min_samples_leaf=1,\n",
    "                max_features='sqrt',\n",
    "                random_state=42,\n",
    "                n_jobs=-1  # Use all CPU cores\n",
    "            )\n",
    "            \n",
    "            self.rf_regressor.fit(X_train_reg, y_train_reg)\n",
    "            y_pred_reg = self.rf_regressor.predict(X_test_reg)\n",
    "            \n",
    "            # Calculate comprehensive regression metrics\n",
    "            reg_mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "            reg_rmse = np.sqrt(reg_mse)\n",
    "            reg_mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "            reg_r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "            reg_explained_var = explained_variance_score(y_test_reg, y_pred_reg)\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            y_mean = np.mean(y_test_reg)\n",
    "            reg_mape = np.mean(np.abs((y_test_reg - y_pred_reg) / y_test_reg)) * 100  # Mean Absolute Percentage Error\n",
    "            \n",
    "            # Feature importance\n",
    "            feature_importance = dict(zip(feature_columns, self.rf_regressor.feature_importances_))\n",
    "            self.feature_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "            \n",
    "            # Cross-validation score for more robust R²\n",
    "            cv_r2_scores = cross_val_score(self.rf_regressor, X, y_reg, cv=5, scoring='r2')\n",
    "            cv_r2_mean = np.mean(cv_r2_scores)\n",
    "            cv_r2_std = np.std(cv_r2_scores)\n",
    "            \n",
    "            results = {\n",
    "                # Classification metrics\n",
    "                'classification_accuracy': class_accuracy,\n",
    "                \n",
    "                # Regression metrics\n",
    "                'regression_mse': reg_mse,\n",
    "                'regression_rmse': reg_rmse,\n",
    "                'regression_mae': reg_mae,\n",
    "                'regression_r2': reg_r2,\n",
    "                'regression_explained_variance': reg_explained_var,\n",
    "                'regression_mape': reg_mape,\n",
    "                \n",
    "                # Cross-validation metrics\n",
    "                'cv_r2_mean': cv_r2_mean,\n",
    "                'cv_r2_std': cv_r2_std,\n",
    "                \n",
    "                # Model details\n",
    "                'feature_importance': self.feature_importance,\n",
    "                'risk_label_encoder': le_risk,\n",
    "                'n_samples': len(df),\n",
    "                'n_features': len(feature_columns),\n",
    "                'target_mean': y_mean,\n",
    "                'target_std': np.std(y_reg)\n",
    "            }\n",
    "            \n",
    "            # Log detailed metrics\n",
    "            logger.info(f\"Model training completed:\")\n",
    "            logger.info(f\"- Classification accuracy: {class_accuracy:.4f}\")\n",
    "            logger.info(f\"- Regression R²: {reg_r2:.4f} ({reg_r2*100:.2f}%)\")\n",
    "            logger.info(f\"- Regression MSE: {reg_mse:.6f}\")\n",
    "            logger.info(f\"- Regression RMSE: {reg_rmse:.4f}\")\n",
    "            logger.info(f\"- Regression MAE: {reg_mae:.4f}\")\n",
    "            logger.info(f\"- Cross-validation R² (mean±std): {cv_r2_mean:.4f}±{cv_r2_std:.4f}\")\n",
    "            logger.info(f\"- Mean Absolute Percentage Error: {reg_mape:.2f}%\")\n",
    "            logger.info(f\"- Explained Variance: {reg_explained_var:.4f}\")\n",
    "            logger.info(f\"- Top 3 features: {list(self.feature_importance.keys())[:3]}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training models: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def make_predictions(self, df: pd.DataFrame, feature_columns: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            feature_columns: List of feature column names\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with predictions added\n",
    "        \"\"\"\n",
    "        logger.info(\"Making predictions with Random Forest models\")\n",
    "        \n",
    "        try:\n",
    "            if self.rf_classifier is None or self.rf_regressor is None:\n",
    "                raise ValueError(\"Models not trained yet. Call train_random_forest_models first.\")\n",
    "            \n",
    "            X = df[feature_columns].values\n",
    "            \n",
    "            # Classification predictions\n",
    "            risk_pred_encoded = self.rf_classifier.predict(X)\n",
    "            risk_pred_proba = self.rf_classifier.predict_proba(X)\n",
    "            \n",
    "            # Get class labels\n",
    "            risk_classes = self.rf_classifier.classes_\n",
    "            \n",
    "            # Convert back to labels\n",
    "            df['Predicted_Risk_Level'] = risk_pred_encoded\n",
    "            df['Risk_Level_Confidence'] = np.max(risk_pred_proba, axis=1)\n",
    "            \n",
    "            # Regression predictions\n",
    "            df['Predicted_Risk_Score'] = self.rf_regressor.predict(X)\n",
    "            \n",
    "            # Add recommendations based on predictions\n",
    "            df['Recommendation'] = df.apply(self._generate_recommendation, axis=1)\n",
    "            \n",
    "            # Add prediction timestamp\n",
    "            df['Prediction_Timestamp'] = datetime.now()\n",
    "            \n",
    "            # Store predictions for metrics calculation\n",
    "            self._last_predictions = df.copy()\n",
    "            \n",
    "            logger.info(f\"Predictions completed for {len(df)} records\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error making predictions: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_recommendation(self, row) -> str:\n",
    "        \"\"\"Generate recommendation based on predictions\"\"\"\n",
    "        risk_score = row.get('Predicted_Risk_Score', 0)\n",
    "        risk_level = row.get('Predicted_Risk_Level', 0)\n",
    "        \n",
    "        if risk_score >= 2.0 or risk_level == 2:  # High risk\n",
    "            return \"Immediate monitoring and proactive maintenance required\"\n",
    "        elif risk_score >= 1.5 or risk_level == 1:  # Medium risk\n",
    "            return \"Enhanced monitoring and scheduled maintenance recommended\"\n",
    "        else:  # Low risk\n",
    "            return \"Standard monitoring sufficient\"\n",
    "    \n",
    "    def save_predictions_to_databricks(self, df: pd.DataFrame, predictions_table: str, mode: str = \"overwrite\"):\n",
    "        \"\"\"\n",
    "        Save predictions to Databricks table\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with predictions\n",
    "            predictions_table: Target table name (e.g., 'default.incident_predictions')\n",
    "            mode: Write mode ('overwrite', 'append')\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving predictions to Databricks table: {predictions_table}\")\n",
    "        \n",
    "        try:\n",
    "            # Select relevant columns for output\n",
    "            output_columns = [\n",
    "                'Asset_Name', 'Category', 'Priority', 'Location_Clean',\n",
    "                'Predicted_Risk_Level', 'Predicted_Risk_Score', 'Risk_Level_Confidence',\n",
    "                'Recommendation', 'Prediction_Timestamp'\n",
    "            ]\n",
    "            \n",
    "            # Add original identifier columns if available\n",
    "            id_columns = ['Asset_Number', 'Incident_Number']\n",
    "            for col in id_columns:\n",
    "                if col in df.columns:\n",
    "                    output_columns.insert(0, col)\n",
    "            \n",
    "            # Filter to existing columns\n",
    "            available_columns = [col for col in output_columns if col in df.columns]\n",
    "            output_df = df[available_columns].copy()\n",
    "            \n",
    "            # Convert to Spark DataFrame\n",
    "            spark_df = self.spark.createDataFrame(output_df)\n",
    "            \n",
    "            # Write to Databricks table\n",
    "            spark_df.write.mode(mode).saveAsTable(predictions_table)\n",
    "            \n",
    "            logger.info(f\"Successfully saved {len(output_df)} predictions to {predictions_table}\")\n",
    "            \n",
    "            # Log sample of results\n",
    "            logger.info(\"Sample predictions:\")\n",
    "            sample_df = output_df.head(5)\n",
    "            for _, row in sample_df.iterrows():\n",
    "                logger.info(f\"Asset: {row.get('Asset_Name', 'N/A')}, \"\n",
    "                          f\"Risk Score: {row.get('Predicted_Risk_Score', 0):.2f}, \"\n",
    "                          f\"Level: {row.get('Predicted_Risk_Level', 'N/A')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving predictions to Databricks: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def save_model_metrics_to_databricks(self, training_results: Dict, metrics_table: str):\n",
    "        \"\"\"\n",
    "        Save comprehensive model performance metrics to Databricks table\n",
    "        \n",
    "        Args:\n",
    "            training_results: Dictionary containing model training results and metrics\n",
    "            metrics_table: Target table name for metrics (e.g., 'default.model_performance_metrics')\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving model metrics to Databricks table: {metrics_table}\")\n",
    "        \n",
    "        try:\n",
    "            # Create comprehensive metrics record\n",
    "            metrics_record = {\n",
    "                'model_run_id': f\"rf_incident_prediction_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "                'model_type': 'Random Forest',\n",
    "                'model_version': '1.0',\n",
    "                'training_timestamp': datetime.now(),\n",
    "                'dataset_size': training_results.get('n_samples', 0),\n",
    "                'feature_count': training_results.get('n_features', 0),\n",
    "                \n",
    "                # Classification Metrics\n",
    "                'classification_accuracy': training_results.get('classification_accuracy', 0.0),\n",
    "                \n",
    "                # Regression Metrics - Primary\n",
    "                'regression_r2': training_results.get('regression_r2', 0.0),\n",
    "                'regression_mse': training_results.get('regression_mse', 0.0),\n",
    "                'regression_rmse': training_results.get('regression_rmse', 0.0),\n",
    "                'regression_mae': training_results.get('regression_mae', 0.0),\n",
    "                'regression_mape': training_results.get('regression_mape', 0.0),\n",
    "                'regression_explained_variance': training_results.get('regression_explained_variance', 0.0),\n",
    "                \n",
    "                # Cross-Validation Metrics\n",
    "                'cv_r2_mean': training_results.get('cv_r2_mean', 0.0),\n",
    "                'cv_r2_std': training_results.get('cv_r2_std', 0.0),\n",
    "                'cv_r2_min': training_results.get('cv_r2_mean', 0.0) - training_results.get('cv_r2_std', 0.0),\n",
    "                'cv_r2_max': training_results.get('cv_r2_mean', 0.0) + training_results.get('cv_r2_std', 0.0),\n",
    "                \n",
    "                # Target Variable Statistics\n",
    "                'target_mean': training_results.get('target_mean', 0.0),\n",
    "                'target_std': training_results.get('target_std', 0.0),\n",
    "                \n",
    "                # Model Performance Classification\n",
    "                'performance_grade': self._classify_model_performance(training_results.get('regression_r2', 0.0)),\n",
    "                'model_quality_score': self._calculate_quality_score(training_results),\n",
    "                \n",
    "                # Feature Importance (Top 5)\n",
    "                'top_feature_1': list(training_results.get('feature_importance', {}).keys())[0] if training_results.get('feature_importance') else None,\n",
    "                'top_feature_1_importance': list(training_results.get('feature_importance', {}).values())[0] if training_results.get('feature_importance') else 0.0,\n",
    "                'top_feature_2': list(training_results.get('feature_importance', {}).keys())[1] if len(training_results.get('feature_importance', {})) > 1 else None,\n",
    "                'top_feature_2_importance': list(training_results.get('feature_importance', {}).values())[1] if len(training_results.get('feature_importance', {})) > 1 else 0.0,\n",
    "                'top_feature_3': list(training_results.get('feature_importance', {}).keys())[2] if len(training_results.get('feature_importance', {})) > 2 else None,\n",
    "                'top_feature_3_importance': list(training_results.get('feature_importance', {}).values())[2] if len(training_results.get('feature_importance', {})) > 2 else 0.0,\n",
    "                \n",
    "                # Model Hyperparameters\n",
    "                'n_estimators': 150,\n",
    "                'max_depth': 12,\n",
    "                'min_samples_split': 3,\n",
    "                'min_samples_leaf': 1,\n",
    "                'max_features': 'sqrt',\n",
    "                \n",
    "                # Business Metrics\n",
    "                'high_risk_assets_predicted': self._count_high_risk_predictions() if hasattr(self, '_last_predictions') else 0,\n",
    "                'model_confidence_avg': self._calculate_avg_confidence() if hasattr(self, '_last_predictions') else 0.0,\n",
    "                \n",
    "                # Data Quality Indicators\n",
    "                'missing_data_percentage': 0.0,  # Will be calculated if needed\n",
    "                'data_quality_score': self._assess_data_quality(training_results),\n",
    "                \n",
    "                # Comments and Notes\n",
    "                'model_notes': f\"Random Forest model trained on {training_results.get('n_samples', 0)} incidents with {training_results.get('n_features', 0)} features\",\n",
    "                'performance_summary': self._generate_performance_summary(training_results)\n",
    "            }\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            metrics_df = pd.DataFrame([metrics_record])\n",
    "            \n",
    "            # Convert to Spark DataFrame\n",
    "            spark_df = self.spark.createDataFrame(metrics_df)\n",
    "            \n",
    "            # Create table if it doesn't exist\n",
    "            self._create_metrics_table_if_not_exists(metrics_table)\n",
    "            \n",
    "            # Write to Databricks table\n",
    "            spark_df.write.mode(\"append\").saveAsTable(metrics_table)\n",
    "            \n",
    "            logger.info(f\"Successfully saved model metrics to {metrics_table}\")\n",
    "            logger.info(f\"Model Run ID: {metrics_record['model_run_id']}\")\n",
    "            logger.info(f\"R²: {metrics_record['regression_r2']:.4f}, MSE: {metrics_record['regression_mse']:.6f}\")\n",
    "            logger.info(f\"Performance Grade: {metrics_record['performance_grade']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving model metrics to Databricks: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _classify_model_performance(self, r2_score: float) -> str:\n",
    "        \"\"\"Classify model performance based on R² score\"\"\"\n",
    "        if r2_score >= 0.95:\n",
    "            return \"EXCELLENT\"\n",
    "        elif r2_score >= 0.90:\n",
    "            return \"VERY_GOOD\"\n",
    "        elif r2_score >= 0.80:\n",
    "            return \"GOOD\"\n",
    "        elif r2_score >= 0.70:\n",
    "            return \"ACCEPTABLE\"\n",
    "        elif r2_score >= 0.50:\n",
    "            return \"MODERATE\"\n",
    "        else:\n",
    "            return \"POOR\"\n",
    "    \n",
    "    def _calculate_quality_score(self, training_results: Dict) -> float:\n",
    "        \"\"\"Calculate overall model quality score (0-100)\"\"\"\n",
    "        try:\n",
    "            r2 = training_results.get('regression_r2', 0.0)\n",
    "            classification_acc = training_results.get('classification_accuracy', 0.0)\n",
    "            cv_r2_mean = training_results.get('cv_r2_mean', 0.0)\n",
    "            cv_r2_std = training_results.get('cv_r2_std', 1.0)\n",
    "            \n",
    "            # Weighted quality score\n",
    "            quality_score = (\n",
    "                r2 * 40 +                          # R² contributes 40%\n",
    "                classification_acc * 30 +          # Classification accuracy 30%\n",
    "                cv_r2_mean * 20 +                  # CV performance 20%\n",
    "                (1 - min(cv_r2_std, 0.5)) * 10    # Low variance bonus 10%\n",
    "            ) * 100\n",
    "            \n",
    "            return min(100.0, max(0.0, quality_score))\n",
    "            \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def _count_high_risk_predictions(self) -> int:\n",
    "        \"\"\"Count number of high-risk asset predictions\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, '_last_predictions') and 'Predicted_Risk_Level' in self._last_predictions.columns:\n",
    "                return int((self._last_predictions['Predicted_Risk_Level'] == 2).sum())  # High risk = 2\n",
    "            return 0\n",
    "        except Exception:\n",
    "            return 0\n",
    "    \n",
    "    def _calculate_avg_confidence(self) -> float:\n",
    "        \"\"\"Calculate average prediction confidence\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, '_last_predictions') and 'Risk_Level_Confidence' in self._last_predictions.columns:\n",
    "                return float(self._last_predictions['Risk_Level_Confidence'].mean())\n",
    "            return 0.0\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def _assess_data_quality(self, training_results: Dict) -> float:\n",
    "        \"\"\"Assess data quality score (0-100)\"\"\"\n",
    "        try:\n",
    "            n_samples = training_results.get('n_samples', 0)\n",
    "            n_features = training_results.get('n_features', 0)\n",
    "            \n",
    "            # Basic data quality assessment\n",
    "            sample_score = min(100, (n_samples / 100) * 50)  # 50 points for adequate samples\n",
    "            feature_score = min(50, n_features * 5)          # 5 points per feature, max 50\n",
    "            \n",
    "            return min(100.0, sample_score + feature_score)\n",
    "            \n",
    "        except Exception:\n",
    "            return 50.0  # Default moderate score\n",
    "    \n",
    "    def _generate_performance_summary(self, training_results: Dict) -> str:\n",
    "        \"\"\"Generate human-readable performance summary\"\"\"\n",
    "        try:\n",
    "            r2 = training_results.get('regression_r2', 0.0)\n",
    "            mse = training_results.get('regression_mse', 0.0)\n",
    "            acc = training_results.get('classification_accuracy', 0.0)\n",
    "            \n",
    "            return f\"R²={r2:.3f} MSE={mse:.4f} ClassAcc={acc:.3f} - Model explains {r2*100:.1f}% of variance\"\n",
    "            \n",
    "        except Exception:\n",
    "            return \"Performance summary unavailable\"\n",
    "    \n",
    "    def _create_metrics_table_if_not_exists(self, metrics_table: str):\n",
    "        \"\"\"Create metrics table if it doesn't exist\"\"\"\n",
    "        try:\n",
    "            # Check if table exists\n",
    "            try:\n",
    "                self.spark.table(metrics_table).limit(1).collect()\n",
    "                logger.info(f\"Metrics table {metrics_table} already exists\")\n",
    "            except Exception:\n",
    "                logger.info(f\"Creating new metrics table: {metrics_table}\")\n",
    "                \n",
    "                # Create table with SQL DDL\n",
    "                create_table_sql = f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {metrics_table} (\n",
    "                    model_run_id STRING,\n",
    "                    model_type STRING,\n",
    "                    model_version STRING,\n",
    "                    training_timestamp TIMESTAMP,\n",
    "                    dataset_size INT,\n",
    "                    feature_count INT,\n",
    "                    \n",
    "                    classification_accuracy DOUBLE,\n",
    "                    \n",
    "                    regression_r2 DOUBLE,\n",
    "                    regression_mse DOUBLE,\n",
    "                    regression_rmse DOUBLE,\n",
    "                    regression_mae DOUBLE,\n",
    "                    regression_mape DOUBLE,\n",
    "                    regression_explained_variance DOUBLE,\n",
    "                    \n",
    "                    cv_r2_mean DOUBLE,\n",
    "                    cv_r2_std DOUBLE,\n",
    "                    cv_r2_min DOUBLE,\n",
    "                    cv_r2_max DOUBLE,\n",
    "                    \n",
    "                    target_mean DOUBLE,\n",
    "                    target_std DOUBLE,\n",
    "                    \n",
    "                    performance_grade STRING,\n",
    "                    model_quality_score DOUBLE,\n",
    "                    \n",
    "                    top_feature_1 STRING,\n",
    "                    top_feature_1_importance DOUBLE,\n",
    "                    top_feature_2 STRING,\n",
    "                    top_feature_2_importance DOUBLE,\n",
    "                    top_feature_3 STRING,\n",
    "                    top_feature_3_importance DOUBLE,\n",
    "                    \n",
    "                    n_estimators INT,\n",
    "                    max_depth INT,\n",
    "                    min_samples_split INT,\n",
    "                    min_samples_leaf INT,\n",
    "                    max_features STRING,\n",
    "                    \n",
    "                    high_risk_assets_predicted INT,\n",
    "                    model_confidence_avg DOUBLE,\n",
    "                    \n",
    "                    missing_data_percentage DOUBLE,\n",
    "                    data_quality_score DOUBLE,\n",
    "                    \n",
    "                    model_notes STRING,\n",
    "                    performance_summary STRING\n",
    "                )\n",
    "                USING DELTA\n",
    "                PARTITIONED BY (DATE(training_timestamp))\n",
    "                \"\"\"\n",
    "                \n",
    "                self.spark.sql(create_table_sql)\n",
    "                logger.info(f\"Successfully created metrics table: {metrics_table}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating metrics table: {str(e)}\")\n",
    "            # Continue anyway - table creation might still work with automatic schema\n",
    "    \n",
    "    def run_full_pipeline(self, source_table: str, predictions_table: str, metrics_table: str = None, retrain: bool = True):\n",
    "        \"\"\"\n",
    "        Run the complete ML pipeline with metrics tracking\n",
    "        \n",
    "        Args:\n",
    "            source_table: Source table with incident data\n",
    "            predictions_table: Target table for predictions\n",
    "            metrics_table: Target table for model performance metrics\n",
    "            retrain: Whether to retrain models\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting full Random Forest prediction pipeline with metrics tracking\")\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Read data\n",
    "            raw_df = self.read_incident_data(source_table)\n",
    "            \n",
    "            # Step 2: Clean and prepare data\n",
    "            clean_df = self.clean_and_prepare_data(raw_df)\n",
    "            \n",
    "            # Step 3: Create features\n",
    "            features_df, feature_columns = self.create_features(clean_df)\n",
    "            \n",
    "            # Step 4: Train models (if needed)\n",
    "            if retrain:\n",
    "                training_results = self.train_random_forest_models(features_df, feature_columns)\n",
    "                self._last_training_results = training_results  # Store for summary report\n",
    "                logger.info(f\"Training completed with R²: {training_results.get('regression_r2', 0):.4f}\")\n",
    "                \n",
    "                # Step 4.1: Save model metrics to Databricks (if metrics table specified)\n",
    "                if metrics_table:\n",
    "                    self.save_model_metrics_to_databricks(training_results, metrics_table)\n",
    "            \n",
    "            # Step 5: Make predictions\n",
    "            predictions_df = self.make_predictions(features_df, feature_columns)\n",
    "            \n",
    "            # Step 6: Save predictions to Databricks\n",
    "            self.save_predictions_to_databricks(predictions_df, predictions_table)\n",
    "            \n",
    "            # Step 7: Generate summary report\n",
    "            self._generate_summary_report(predictions_df)\n",
    "            \n",
    "            logger.info(\"Pipeline completed successfully!\")\n",
    "            \n",
    "            # Return summary for external use\n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'predictions_table': predictions_table,\n",
    "                'metrics_table': metrics_table,\n",
    "                'records_processed': len(predictions_df),\n",
    "                'assets_analyzed': predictions_df['Asset_Name'].nunique(),\n",
    "                'model_performance': self._last_training_results if hasattr(self, '_last_training_results') else None\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_summary_report(self, df: pd.DataFrame):\n",
    "        \"\"\"Generate comprehensive summary report of predictions with model metrics\"\"\"\n",
    "        logger.info(\"=== COMPREHENSIVE PREDICTION SUMMARY REPORT ===\")\n",
    "        \n",
    "        try:\n",
    "            total_assets = df['Asset_Name'].nunique()\n",
    "            total_predictions = len(df)\n",
    "            \n",
    "            # Risk level distribution\n",
    "            if 'Predicted_Risk_Level' in df.columns:\n",
    "                risk_dist = df['Predicted_Risk_Level'].value_counts()\n",
    "                logger.info(f\"Risk Level Distribution: {dict(risk_dist)}\")\n",
    "            \n",
    "            # Top risk assets\n",
    "            if 'Predicted_Risk_Score' in df.columns:\n",
    "                top_risk = df.nlargest(5, 'Predicted_Risk_Score')[['Asset_Name', 'Predicted_Risk_Score']]\n",
    "                logger.info(\"Top 5 Risk Assets:\")\n",
    "                for _, row in top_risk.iterrows():\n",
    "                    logger.info(f\"  - {row['Asset_Name']}: {row['Predicted_Risk_Score']:.3f}\")\n",
    "                \n",
    "                # Risk score statistics\n",
    "                risk_stats = df['Predicted_Risk_Score'].describe()\n",
    "                logger.info(f\"Risk Score Statistics:\")\n",
    "                logger.info(f\"  - Mean: {risk_stats['mean']:.3f}\")\n",
    "                logger.info(f\"  - Std Dev: {risk_stats['std']:.3f}\")\n",
    "                logger.info(f\"  - Min: {risk_stats['min']:.3f}\")\n",
    "                logger.info(f\"  - Max: {risk_stats['max']:.3f}\")\n",
    "            \n",
    "            # Feature importance\n",
    "            if self.feature_importance:\n",
    "                logger.info(\"Top 5 Feature Importance:\")\n",
    "                for feature, importance in list(self.feature_importance.items())[:5]:\n",
    "                    logger.info(f\"  - {feature}: {importance:.4f} ({importance*100:.2f}%)\")\n",
    "            \n",
    "            # Model performance summary\n",
    "            logger.info(\"=== MODEL PERFORMANCE METRICS ===\")\n",
    "            if hasattr(self, '_last_training_results'):\n",
    "                results = self._last_training_results\n",
    "                logger.info(f\"R-squared (R²): {results.get('regression_r2', 0):.4f} ({results.get('regression_r2', 0)*100:.2f}%)\")\n",
    "                logger.info(f\"Mean Squared Error (MSE): {results.get('regression_mse', 0):.6f}\")\n",
    "                logger.info(f\"Root Mean Squared Error (RMSE): {results.get('regression_rmse', 0):.4f}\")\n",
    "                logger.info(f\"Mean Absolute Error (MAE): {results.get('regression_mae', 0):.4f}\")\n",
    "                logger.info(f\"Mean Absolute Percentage Error (MAPE): {results.get('regression_mape', 0):.2f}%\")\n",
    "                logger.info(f\"Cross-validation R²: {results.get('cv_r2_mean', 0):.4f}±{results.get('cv_r2_std', 0):.4f}\")\n",
    "                logger.info(f\"Classification Accuracy: {results.get('classification_accuracy', 0):.4f}\")\n",
    "                \n",
    "                # Model interpretation\n",
    "                r2 = results.get('regression_r2', 0)\n",
    "                if r2 > 0.9:\n",
    "                    logger.info(\"✅ EXCELLENT model performance (R² > 0.9)\")\n",
    "                elif r2 > 0.8:\n",
    "                    logger.info(\"✅ VERY GOOD model performance (R² > 0.8)\")  \n",
    "                elif r2 > 0.7:\n",
    "                    logger.info(\"✅ GOOD model performance (R² > 0.7)\")\n",
    "                elif r2 > 0.5:\n",
    "                    logger.info(\"⚠️ MODERATE model performance (R² > 0.5)\")\n",
    "                else:\n",
    "                    logger.info(\"❌ POOR model performance (R² < 0.5)\")\n",
    "                \n",
    "                logger.info(f\"The model explains {r2*100:.1f}% of the variance in risk scores\")\n",
    "            \n",
    "            logger.info(f\"\\nTotal assets analyzed: {total_assets}\")\n",
    "            logger.info(f\"Total predictions made: {total_predictions}\")\n",
    "            logger.info(\"=== END REPORT ===\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating summary: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function with metrics tracking - FIXED VERSION\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    SOURCE_TABLE = \"sd_bdc_demo.default.service_now_only\" # Replace with your table name\n",
    "    PREDICTIONS_TABLE = \"sd_bdc_demo.default.service_now_rf_predictions\" # Replace with your predictions table\n",
    "    METRICS_TABLE = \"sd_bdc_demo.default.service_now_rf_model_performance_metrics\"  # New metrics table\n",
    "    \n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DatabricksRandomForestPredictor()\n",
    "        \n",
    "        # Run full pipeline with metrics tracking\n",
    "        results = predictor.run_full_pipeline(\n",
    "            source_table=SOURCE_TABLE,\n",
    "            predictions_table=PREDICTIONS_TABLE,  # Fixed: using correct parameter name\n",
    "            metrics_table=METRICS_TABLE,  # Enable metrics tracking\n",
    "            retrain=True\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Random Forest prediction pipeline completed successfully!\")\n",
    "        print(f\"\uD83D\uDCCA Results: {results}\")\n",
    "        print(f\"\uD83D\uDCC8 Predictions saved to: {PREDICTIONS_TABLE}\")\n",
    "        print(f\"\uD83D\uDCCB Model metrics saved to: {METRICS_TABLE}\")\n",
    "        \n",
    "        # Query and display recent metrics\n",
    "        try:\n",
    "            recent_metrics = predictor.spark.sql(f\"\"\"\n",
    "                SELECT model_run_id, training_timestamp, regression_r2, regression_mse, \n",
    "                       performance_grade, model_quality_score\n",
    "                FROM {METRICS_TABLE}\n",
    "                ORDER BY training_timestamp DESC\n",
    "                LIMIT 1\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            if recent_metrics:\n",
    "                metric = recent_metrics[0]\n",
    "                print(f\"\\n\uD83C\uDFAF Latest Model Performance:\")\n",
    "                print(f\"   - Run ID: {metric['model_run_id']}\")\n",
    "                print(f\"   - R²: {metric['regression_r2']:.4f}\")\n",
    "                print(f\"   - MSE: {metric['regression_mse']:.6f}\")\n",
    "                print(f\"   - Grade: {metric['performance_grade']}\")\n",
    "                print(f\"   - Quality Score: {metric['model_quality_score']:.1f}/100\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not retrieve metrics summary: {str(e)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Random Forest Service Now initial subset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}